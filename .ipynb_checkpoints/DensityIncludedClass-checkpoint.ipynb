{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d0146dc-b83e-45fa-8423-af36738ba004",
   "metadata": {},
   "source": [
    "## Contribution per distance/density to overall visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "177b0300-ffb7-426d-bf34-47859ae6503a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Number of Visitors from Each Distance:\n",
      "[246349.32784016 213723.67207287 180755.30112423 148806.53719399\n",
      " 118825.60543717  91539.55633158]\n",
      "\n",
      "Total Estimated Visitors by Distance: 1000000.0\n",
      "\n",
      "Total Visitors from Each Density:\n",
      "Density 1k: 9324 visitors\n",
      "Density 5k: 43427 visitors\n",
      "Density 10k: 78167 visitors\n",
      "Density 20k: 128660 visitors\n",
      "Density 50k: 206686 visitors\n",
      "Density 100k: 252781 visitors\n",
      "Density 250k: 280955 visitors\n",
      "\n",
      "Total Estimated Visitors by Density: 1000000.0000000001\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def estimate_visitor_distribution(total_visitors, prob_matrix, distances, densities):\n",
    "    # Calculate the proportion of total visitors from each density based on their relative values\n",
    "    density_norm_factor = prob_matrix.sum(axis=0)\n",
    "    density_norm = densities*density_norm_factor\n",
    "    density_proportions = density_norm/np.sum(density_norm)\n",
    "    \n",
    "    # Calculate the total number of visitors attributed to each density\n",
    "    visitors_per_density = density_proportions * total_visitors\n",
    "\n",
    "    # Create an empty array to store the estimated visitors for each distance across all densities\n",
    "    estimated_visitors_by_distance = np.zeros(len(distances))\n",
    "\n",
    "    # Distribute each density's visitors across distances according to the probability matrix\n",
    "    for i in range(len(densities)):\n",
    "        estimated_visitors_by_distance += prob_matrix[:, i] * visitors_per_density[i]\n",
    "\n",
    "    # Normalize the results to ensure they sum to the total number of visitors\n",
    "    estimated_visitors_by_distance *= (total_visitors / np.sum(estimated_visitors_by_distance))\n",
    "\n",
    "    return estimated_visitors_by_distance, visitors_per_density\n",
    "\n",
    "# Define the probability matrix, distances, and densities\n",
    "prob_matrix = np.array([\n",
    "    [0.999, 0.989, 0.966, 0.906, 0.717, 0.496, 0.236],\n",
    "    [0.999, 0.979, 0.941, 0.849, 0.610, 0.387, 0.172],\n",
    "    [0.997, 0.962, 0.899, 0.767, 0.490, 0.288, 0.123],\n",
    "    [0.995, 0.933, 0.834, 0.659, 0.372, 0.206, 0.086],\n",
    "    [0.989, 0.883, 0.739, 0.531, 0.268, 0.142, 0.060],\n",
    "    [0.978, 0.803, 0.615, 0.398, 0.184, 0.096, 0.041]\n",
    "])\n",
    "distances = np.array([0, 1, 2, 3, 4, 5])  # in miles\n",
    "densities = np.array([1, 5, 10, 20, 50, 100, 250])  # thousands of people within a 5-mile radius\n",
    "\n",
    "total_visitors = 1000000  # total number of visitors\n",
    "estimated_visitors, visitors_from_each_density = estimate_visitor_distribution(total_visitors, prob_matrix, distances, densities)\n",
    "\n",
    "print(\"Estimated Number of Visitors from Each Distance:\")\n",
    "print(estimated_visitors)\n",
    "print(\"\\nTotal Estimated Visitors by Distance:\", np.sum(estimated_visitors))\n",
    "\n",
    "# Print total visitors from each density\n",
    "print(\"\\nTotal Visitors from Each Density:\")\n",
    "for density, visitors in zip(densities, visitors_from_each_density):\n",
    "    print(f\"Density {density}k: {visitors:.0f} visitors\")\n",
    "\n",
    "print(\"\\nTotal Estimated Visitors by Density:\", np.sum(visitors_from_each_density))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d221c93-f004-4eb4-b1db-532508f92b43",
   "metadata": {},
   "source": [
    "## Scaling expenditure per consumer by square footage of store type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "0a13701b-5581-48af-ba02-710f9480ed0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weekly_visits = 167*1e6\n",
    "avg_spend = (393247*1e6) / (8684*1e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08270dee-7021-4af1-b0a3-bb088e32c7d7",
   "metadata": {},
   "source": [
    "## Monte Carlo Visitors + Average Spend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "17eb22f1-0756-42dc-b5c2-07b99d2d48c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Number of Visitors from Each Distance:\n",
      "[9.07782953e+09 7.34148075e+09 5.67055513e+09 4.18591796e+09\n",
      " 2.96644468e+09 2.02683527e+09]\n",
      "\n",
      "Total Estimated Visitors by Distance: 31269063307.855804\n",
      "\n",
      "Total Visitors from Each Density:\n",
      "Density 1k: 85003165 visitors\n",
      "Density 5k: 385240087 visitors\n",
      "Density 10k: 716352645 visitors\n",
      "Density 20k: 1060921188 visitors\n",
      "Density 50k: 1816019098 visitors\n",
      "Density 100k: 2219899563 visitors\n",
      "Density 250k: 2400564254 visitors\n",
      "\n",
      "Visitors by Store Type:\n",
      "Supercenters: 7598007623 visitors\n",
      "Discount Stores: 85064382 visitors\n",
      "Neighborhood Markets: 1000927995 visitors\n",
      "\n",
      "Visitors by Store Type:\n",
      "Supercenters: 7598007623 total visitors, 2126506 visitors per store\n",
      "Discount Stores: 85064382 total visitors, 229904 visitors per store\n",
      "Neighborhood Markets: 1000927995 total visitors, 1252726 visitors per store\n",
      "\n",
      "Total Estimated Visitors by Store Type: 8684000000.0\n",
      "\n",
      "Total Estimated Visitors by Density: 8684000000.0\n",
      "Average Estimated Visitors: 7597459853.102853 85546850.56191175 1000993296.3352361\n",
      "Standard Deviation of Visitors: 15611921.804656627 675566.5581900654 15976631.560191866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Supercenters': 7598007622.58742,\n",
       " 'Discount Stores': 85064382.48260556,\n",
       " 'Neighborhood Markets': 1000927994.9299742}"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def estimate_visitor_distribution_by_store_type(total_visitors, prob_matrix, distances, densities, store_data, num_simulations=1000):\n",
    "    # Calculate the proportion of total visitors from each density based on their relative values\n",
    "    # density_norm_factor = prob_matrix.sum(axis=0)\n",
    "    # density_norm = densities * density_norm_factor\n",
    "    # density_proportions = density_norm / np.sum(density_norm)\n",
    "\n",
    "    # Calculate the total number of visitors attributed to each density\n",
    "    visitor_results=[]\n",
    "    for _ in range(num_simulations):\n",
    "        # Randomly adjust probabilities by up to Â±10% to simulate changes in demographics or economic conditions\n",
    "        adjustment_factor = 1 + (np.random.rand(*prob_matrix.shape) - 0.5) * 0.2\n",
    "        adjusted_matrix = prob_matrix * adjustment_factor\n",
    "        density_norm_factor = adjusted_matrix.sum(axis=0)\n",
    "        density_norm = densities * density_norm_factor\n",
    "        density_proportions = density_norm / np.sum(density_norm)\n",
    "        \n",
    "        visitors_per_density = density_proportions * total_visitors\n",
    "\n",
    "    # Calculate total visitors based on store type and density eligibility\n",
    "        total_visitors_by_type = {}     \n",
    "        for store_type, data in store_data.items():\n",
    "            # Adjust the total visitors according to the store type specifics\n",
    "            footprint_ratio = data['avg_sqft'] / np.mean([d['avg_sqft'] for d in store_data.values()])\n",
    "            location_factor = data['locations'] / sum(d['locations'] for d in store_data.values())\n",
    "    \n",
    "            # Apply density eligibility\n",
    "            eligible_visitors_per_density = visitors_per_density * data['density_eligibility']\n",
    "            eligible_total_visitors = eligible_visitors_per_density.sum()  # Sum of eligible visitors per density\n",
    "    \n",
    "            # Calculate the share of visitors for this store type\n",
    "            raw_share = eligible_total_visitors * footprint_ratio * location_factor\n",
    "            total_visitors_by_type[store_type] = raw_share\n",
    "       \n",
    "    \n",
    "        # Normalize the visitor distribution to match the total number of visitors\n",
    "        sum_raw_shares = sum(total_visitors_by_type.values())\n",
    "        normalization_factor = total_visitors / sum_raw_shares\n",
    "        for store_type in total_visitors_by_type:\n",
    "            total_visitors_by_type[store_type] *= normalization_factor\n",
    "        \n",
    "        visitor_results.append(list(total_visitors_by_type.values()))\n",
    "\n",
    "        # Calculate and distribute visitors\n",
    "        estimated_visitors_by_distance = np.zeros(len(distances))\n",
    "        for store_type, visitors in total_visitors_by_type.items():\n",
    "            #visitor_results.append({store_type:visitors})\n",
    "            for i, is_eligible in enumerate(store_data[store_type]['density_eligibility']):\n",
    "                if is_eligible:\n",
    "                    estimated_visitors_by_distance += prob_matrix[:, i] * (eligible_visitors_per_density[i] * normalization_factor)\n",
    "\n",
    "    return estimated_visitors_by_distance, visitors_per_density, total_visitors_by_type, visitor_results\n",
    "\n",
    "# Store-specific data with density eligibility\n",
    "store_data = {\n",
    "    'Supercenters': {'locations': 3573, 'avg_sqft': 178000, 'density_eligibility': np.array([1, .8, .8, .8, 0.3, 0, 0])},\n",
    "    'Discount Stores': {'locations': 370, 'avg_sqft': 105000, 'density_eligibility': np.array([0, .2, .2, .2, 0, 0, 0])},\n",
    "    'Neighborhood Markets': {'locations': 799, 'avg_sqft': 42000, 'density_eligibility': np.array([0, 0, 0, 0, 0.7, 1, 1])}\n",
    "}\n",
    "\n",
    "estimated_visitors, visitors_from_each_density, visitors_by_store_type, visitor_results = estimate_visitor_distribution_by_store_type(\n",
    "    total_visitors=total_annual_visits, prob_matrix=prob_matrix, distances=distances, densities=densities, store_data=store_data)\n",
    "\n",
    "print(\"Estimated Number of Visitors from Each Distance:\")\n",
    "print(estimated_visitors)\n",
    "print(\"\\nTotal Estimated Visitors by Distance:\", np.sum(estimated_visitors))\n",
    "\n",
    "# Print total visitors from each density\n",
    "print(\"\\nTotal Visitors from Each Density:\")\n",
    "for density, visitors in zip(densities, visitors_from_each_density):\n",
    "    print(f\"Density {density}k: {visitors:.0f} visitors\")\n",
    "\n",
    "# Print visitors by store type\n",
    "print(\"\\nVisitors by Store Type:\")\n",
    "for store_type, visitors in visitors_by_store_type.items():\n",
    "    print(f\"{store_type}: {visitors:.0f} visitors\")\n",
    "\n",
    "# Print visitors by store type\n",
    "print(\"\\nVisitors by Store Type:\")\n",
    "\n",
    "visitors_per_store_by_type = {}\n",
    "for store_type, visitors in visitors_by_store_type.items():\n",
    "    visitors_per_store = visitors / store_data[store_type]['locations']\n",
    "    print(f\"{store_type}: {visitors:.0f} total visitors, {visitors_per_store:.0f} visitors per store\")\n",
    "    visitors_per_store_by_type[store_type] = visitors_per_store\n",
    "\n",
    "print(\"\\nTotal Estimated Visitors by Store Type:\", sum(visitors_by_store_type.values()))\n",
    "\n",
    "print(\"\\nTotal Estimated Visitors by Density:\", np.sum(visitors_from_each_density)) \n",
    "visitor_results = np.array(visitor_results)\n",
    "#visitor_results[:,1]\n",
    "# Analyze results\n",
    "print(\"Average Estimated Visitors:\", np.mean(visitor_results[:,0]),np.mean(visitor_results[:,1]),np.mean(visitor_results[:,2]))\n",
    "print(\"Standard Deviation of Visitors:\", np.std(visitor_results[:,0]),np.std(visitor_results[:,1]),np.std(visitor_results[:,2]))\n",
    "visitors_by_store_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "8adad266-24ef-4f75-9f12-0a8fe97613fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Normalized Spending per Store:\n",
      "Supercenters: $343048813610.92\n",
      "Discount Stores: $2946479649.83\n",
      "Neighborhood Markets: $47251706739.25\n",
      "\n",
      "Average Percent Spending by Store Type:\n",
      "Supercenters: 87.23%\n",
      "Discount Stores: 0.75%\n",
      "Neighborhood Markets: 12.02%\n",
      "\n",
      "Average Visitor Spending by Store Type:\n",
      "Supercenters: $45.19\n",
      "Discount Stores: $34.72\n",
      "Neighborhood Markets: $46.90\n",
      "Average Normalized Spending Total across Simulations: 393247000000.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Sample data\n",
    "visitors_data = {\n",
    "    'Supercenters': {'total_visitors': 7591667114, 'visitors_per_store': 2124732},\n",
    "    'Discount Stores': {'total_visitors': 84852921, 'visitors_per_store': 229332},\n",
    "    'Neighborhood Markets': {'total_visitors': 1007479965, 'visitors_per_store': 1260926}\n",
    "}\n",
    "total_revenue = total_net_sales  # Example total revenue\n",
    "\n",
    "# Define base average spending per visitor for each store type, initially unnormalized\n",
    "base_spending_per_visitor = {\n",
    "    'Supercenters': avg_spend,  # Hypothetical average spending per visitor\n",
    "    'Discount Stores': avg_spend,\n",
    "    'Neighborhood Markets': avg_spend\n",
    "}\n",
    "\n",
    "# Define potential variation ranges for scaling factors (e.g., influenced by e-commerce)\n",
    "scaling_factor_ranges = {\n",
    "    'Supercenters': (1.2, 1.4),\n",
    "    'Discount Stores': (.5, 1.5),\n",
    "    'Neighborhood Markets': (1, 1.7)\n",
    "}\n",
    "\n",
    "# Number of simulations\n",
    "n_simulations = 10000\n",
    "\n",
    "def monte_carlo_spending_adjustment(visitors_data, base_spending_per_visitor, scaling_factor_ranges, n_simulations, total_revenue):\n",
    "    results = []\n",
    "\n",
    "    for _ in range(n_simulations):\n",
    "        # Apply random scaling factors to the base spending per visitor\n",
    "        temp_spending = {store_type: base_spending_per_visitor[store_type] * np.random.uniform(*scaling_factor_ranges[store_type])\n",
    "                         for store_type in base_spending_per_visitor}\n",
    "        \n",
    "        # Normalize the spending using your existing function\n",
    "        normalized_spending, normalized_total, percent_spending = normalize_spending(visitors_data, temp_spending, total_revenue)\n",
    "        results.append((normalized_spending, normalized_total, percent_spending))\n",
    "    \n",
    "    return results\n",
    "\n",
    "def normalize_spending(visitors_data, base_spending_per_visitor, total_revenue):\n",
    "    # Calculate initial total spending\n",
    "    initial_total_spending = sum(base_spending_per_visitor[store_type] * data['total_visitors']\n",
    "                                 for store_type, data in visitors_data.items())\n",
    "    \n",
    "    # Normalization factor to match the total revenue\n",
    "    normalization_factor = total_revenue / initial_total_spending\n",
    "    \n",
    "    # Adjusted spending per visitor\n",
    "    normalized_spending_per_visitor = {store_type: base_spending_per_visitor[store_type] * normalization_factor\n",
    "                                       for store_type in base_spending_per_visitor}\n",
    "    \n",
    "    normalized_spending_total = sum(normalized_spending_per_visitor[store_type] * data['total_visitors']\n",
    "                                    for store_type, data in visitors_data.items())\n",
    "\n",
    "    normalized_spending_per_store = {store_type: normalized_spending_per_visitor[store_type] * data['total_visitors']\n",
    "                                       for store_type, data in visitors_data.items()}\n",
    "    \n",
    "    percent_spending_per_store = {store_type: normalized_spending_per_store[store_type] / normalized_spending_total\n",
    "                                       for store_type in normalized_spending_per_store}\n",
    "    \n",
    "    return normalized_spending_per_visitor, normalized_spending_total, percent_spending_per_store\n",
    "\n",
    "def calculate_averages(simulation_results):\n",
    "    # Initialize dictionaries to accumulate totals for averaging later\n",
    "    total_normalized_spending_per_store = {store_type: 0 for store_type in visitors_data}\n",
    "    total_percent_spending_per_store = {store_type: 0 for store_type in visitors_data}\n",
    "    total_normalized_spending_per_visitor = {store_type: 0 for store_type in visitors_data}\n",
    "    \n",
    "    # Accumulate totals from each simulation\n",
    "    for normalized_spending, normalized_total, percent_spending in simulation_results:\n",
    "        for store_type in visitors_data:\n",
    "            total_normalized_spending_per_store[store_type] += normalized_spending[store_type] * visitors_data[store_type]['total_visitors']\n",
    "            total_percent_spending_per_store[store_type] += percent_spending[store_type]\n",
    "            total_normalized_spending_per_visitor[store_type] += normalized_spending[store_type]\n",
    "            \n",
    "    # Calculate averages by dividing by the number of simulations\n",
    "    avg_normalized_spending_per_store = {store_type: total / n_simulations for store_type, total in total_normalized_spending_per_store.items()}\n",
    "    avg_percent_spending_per_store = {store_type: total / n_simulations for store_type, total in total_percent_spending_per_store.items()}\n",
    "    avg_normalized_spending_per_visitor = {store_type: total / n_simulations for store_type, total in total_normalized_spending_per_visitor.items()}\n",
    "    \n",
    "    return avg_normalized_spending_per_store, avg_percent_spending_per_store, avg_normalized_spending_per_visitor\n",
    "\n",
    "\n",
    "\n",
    "# Run the Monte Carlo simulation\n",
    "simulation_results = monte_carlo_spending_adjustment(visitors_data, base_spending_per_visitor, scaling_factor_ranges, n_simulations, total_revenue)\n",
    "\n",
    "\n",
    "# Get averages from the simulation results\n",
    "avg_normalized_spending_per_store, avg_percent_spending_per_store, avg_normalized_spending_per_visitor = calculate_averages(simulation_results)\n",
    "\n",
    "# Printing the averages\n",
    "print(\"Average Normalized Spending per Store:\")\n",
    "for store_type, avg_spending in avg_normalized_spending_per_store.items():\n",
    "    print(f\"{store_type}: ${avg_spending:.2f}\")\n",
    "\n",
    "print(\"\\nAverage Percent Spending by Store Type:\")\n",
    "for store_type, avg_percent in avg_percent_spending_per_store.items():\n",
    "    print(f\"{store_type}: {avg_percent * 100:.2f}%\")\n",
    "\n",
    "print(\"\\nAverage Visitor Spending by Store Type:\")\n",
    "for store_type, avg_spending in avg_normalized_spending_per_visitor.items():\n",
    "    print(f\"{store_type}: ${avg_spending:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example output\n",
    "average_results = np.mean([result[1] for result in simulation_results])\n",
    "print(\"Average Normalized Spending Total across Simulations:\", average_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "50ad79fa-bb45-4011-bfff-89641602846a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Estimated Visitors: 639337.2187199689\n",
      "Standard Deviation of Visitors: 7725.335836409974\n",
      "Average Estimated Revenue: 31916716.358955197\n",
      "Standard Deviation of Revenue: 3281407.26860883\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e0ba436-b54e-4b31-9df9-f9d2f78e6fab",
   "metadata": {},
   "source": [
    "## The Expansion Simulation Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "9d856fb8-39a8-43e2-a491-baf7cb1d50be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1,   5,  10,  20,  50, 100, 250]),\n",
       " array([[0.999, 0.989, 0.966, 0.906, 0.717, 0.496, 0.236],\n",
       "        [0.999, 0.979, 0.941, 0.849, 0.61 , 0.387, 0.172],\n",
       "        [0.997, 0.962, 0.899, 0.767, 0.49 , 0.288, 0.123],\n",
       "        [0.995, 0.933, 0.834, 0.659, 0.372, 0.206, 0.086],\n",
       "        [0.989, 0.883, 0.739, 0.531, 0.268, 0.142, 0.06 ],\n",
       "        [0.978, 0.803, 0.615, 0.398, 0.184, 0.096, 0.041]]))"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "densities, prob_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "0e23e40a-4bf4-4d00-88f1-409e327dba3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NeighborhoodMarketExpansionModel:\n",
    "    def __init__(self, demographic_data, market_conditions, financials, investment_factors, historical_data, store_data, prob_matrix, distances, densities, avg_spending_per_visitor):\n",
    "        self.demographic_data = demographic_data\n",
    "        self.market_conditions = market_conditions\n",
    "        self.financials = financials\n",
    "        self.investment_factors = investment_factors\n",
    "        self.historical_data = historical_data\n",
    "        self.store_data = store_data\n",
    "        self.prob_matrix = prob_matrix\n",
    "        self.distances = distances\n",
    "        self.densities = densities\n",
    "        self.avg_spending_per_visitor = avg_spending_per_visitor\n",
    "        self.visitor_estimates = None\n",
    "\n",
    "    \n",
    "    def calculate_cagr(self, initial_value, final_value, periods):\n",
    "        if periods <= 0:\n",
    "            raise ValueError(\"Periods must be greater than zero for CAGR calculation.\")\n",
    "        return (final_value / initial_value) ** (1 / periods) - 1\n",
    "\n",
    "    def calculate_cagrs(self):\n",
    "        revenue_cagr = self.calculate_cagr(\n",
    "            self.historical_data['initial_revenue'],\n",
    "            self.historical_data['final_revenue'],\n",
    "            self.historical_data['periods'])\n",
    "        cogs_cagr = self.calculate_cagr(\n",
    "            self.historical_data['initial_cogs'],\n",
    "            self.historical_data['final_cogs'],\n",
    "            self.historical_data['periods'])\n",
    "        ecommerce_cagr = self.calculate_cagr(\n",
    "            self.historical_data['initial_ecommerce'],\n",
    "            self.historical_data['final_ecommerce'],\n",
    "            self.historical_data['periods'])\n",
    "        return revenue_cagr, cogs_cagr, ecommerce_cagr\n",
    "\n",
    "    def calculate_cannibalization_effect(self, existing_store_sales, new_store_openings):\n",
    "        cannibalization_rate = self.market_conditions.get('cannibalization_rate', 0.01)\n",
    "        adjusted_sales = existing_store_sales * (1 - cannibalization_rate * new_store_openings)\n",
    "        return adjusted_sales\n",
    "\n",
    "    def dynamic_ecommerce_growth(self, current_sales):\n",
    "        ecommerce_growth_factor = self.market_conditions.get('ecommerce_growth_factor', 0.05)\n",
    "        market_saturation = self.market_conditions.get('market_saturation', 0.1)\n",
    "        distribution_efficiency = self.market_conditions.get('distribution_efficiency', 0.9)\n",
    "        adjusted_growth_rate = ecommerce_growth_factor * (1 - market_saturation) * distribution_efficiency\n",
    "        adjusted_sales = current_sales * (1 + adjusted_growth_rate)\n",
    "        return adjusted_sales\n",
    "\n",
    "    def adjust_operational_costs(self, base_cost):\n",
    "        proximity_factor = self.market_conditions.get('proximity_factor', 0.2)\n",
    "        distribution_center_proximity = self.market_conditions.get('distribution_center_proximity', 0.5)\n",
    "        adjusted_cost = base_cost * (1 - proximity_factor * distribution_center_proximity)\n",
    "        return adjusted_cost\n",
    "\n",
    "    def labor_investment_needed(self, current_market_share, target_market_share, community_opposition_strength):\n",
    "        labor_investment_increase = 0\n",
    "        while current_market_share < target_market_share:\n",
    "            current_market_share *= (1 + 0.01 * (1 - community_opposition_strength))\n",
    "            labor_investment_increase += 0.01\n",
    "        return labor_investment_increase\n",
    "\n",
    "    def evaluate_labor_investment_impact(self, labor_costs, initial_profit_margin, labor_investment_increase):\n",
    "        adjusted_labor_costs = labor_costs * (1 + labor_investment_increase)\n",
    "        adjusted_profit_margin = initial_profit_margin * (1 - 0.05 * labor_investment_increase)\n",
    "        return adjusted_labor_costs, adjusted_profit_margin\n",
    "\n",
    "\n",
    "    def estimate_visitors(self, total_visitors):\n",
    "        # Call the visitor distribution estimation function\n",
    "        estimated_visitors, visitors_from_each_density, visitors_by_store_type, visitor_results = estimate_visitor_distribution_by_store_type(\n",
    "            total_visitors=total_visitors, prob_matrix=self.prob_matrix, distances=self.distances, densities=self.densities, store_data=self.store_data)\n",
    "        self.visitor_estimates = {\n",
    "            'estimated_visitors': estimated_visitors,\n",
    "            'visitors_from_each_density': visitors_from_each_density,\n",
    "            'visitors_by_store_type': visitors_by_store_type,\n",
    "            'visitor_results': visitor_results\n",
    "        }\n",
    "        return self.visitor_estimates\n",
    "\n",
    "    \n",
    "    def run_monte_carlo_simulations(self, num_simulations=1000, total_visitors=167000000):\n",
    "        # Estimate visitor distribution\n",
    "        self.estimate_visitors(total_visitors)\n",
    "\n",
    "        results = []\n",
    "        for _ in range(num_simulations):\n",
    "            # Example of utilizing visitor counts\n",
    "            for store_type, visitors in self.visitor_estimates['visitors_by_store_type'].items():\n",
    "                current_sales = visitors * self.avg_spending_per_visitor.get(store_type, 20)  # Assuming a default average spend if not specified\n",
    "                adjusted_sales = self.calculate_cannibalization_effect(current_sales, np.random.randint(1, 10))\n",
    "                adjusted_sales = self.dynamic_ecommerce_growth(adjusted_sales)\n",
    "                adjusted_costs = self.adjust_operational_costs(self.financials['base_operational_cost'])\n",
    "                net_profit = adjusted_sales - adjusted_costs\n",
    "                results.append(net_profit)\n",
    "\n",
    "        average_profit = np.mean(results)\n",
    "        profit_std_dev = np.std(results)\n",
    "        return average_profit, profit_std_dev\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "7342431d-36a6-4547-8a12-74b426e2f56f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1002461419.5788153"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "16861918-3417-4dfe-8155-d9852a9e833a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Supercenters': 7628249334.935126, 'Discount Stores': 86624917.15886736, 'Neighborhood Markets': 969125747.9060061}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: (1211407.1848825077, 100),\n",
       " 2: (1209894.816362055, 100),\n",
       " 3: (1208386.219334172, 100),\n",
       " 4: (1206881.3797086005, 100),\n",
       " 5: (1205380.2834651817, 100),\n",
       " 6: (1203882.9166534238, 100),\n",
       " 7: (1202389.2653920671, 100),\n",
       " 8: (1200899.3158686568, 100),\n",
       " 9: (1199413.0543391164, 99.95108786159304)}"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimated_visitors, visitors_from_each_density, visitors_by_store_type, visitor_results = estimate_visitor_distribution_by_store_type(\n",
    "total_visitors=total_annual_visits, prob_matrix=prob_matrix, distances=distances, densities=densities, store_data=store_data)\n",
    "print(visitors_by_store_type)\n",
    "def simulate_store_numbers(visitors_by_store_type, optimal_visitors, max_stores, store_type):\n",
    "    results = {}\n",
    "    for num_stores in range(1, max_stores + 1):\n",
    "        visitors_per_store = visitors_by_store_type[store_type] / (store_data[store_type]['locations'] + num_stores)\n",
    "        if visitors_per_store < optimal_visitors:\n",
    "            # Assuming profitability drops if the store is underutilized\n",
    "            profitability = visitors_per_store / optimal_visitors * 100  # as percentage\n",
    "        else:\n",
    "            # Assuming maximum profitability is reached at optimal visitors per store\n",
    "            profitability = 100\n",
    "\n",
    "        results[num_stores] = (visitors_per_store, profitability)\n",
    "        if visitors_per_store < optimal_visitors:\n",
    "            break  # Stop if stores are not reaching optimal visitor count\n",
    "\n",
    "    return results\n",
    "\n",
    "# Optimal visitors per store for efficient operation\n",
    "optimal_visitors_per_store = 1200000\n",
    "\n",
    "max_possible_stores = 50  # Set based on your market size and investment capability\n",
    "simulation_results = simulate_store_numbers(visitors_by_store_type, optimal_visitors_per_store, max_possible_stores, 'Neighborhood Markets')\n",
    "\n",
    "# Find the number of stores with the highest profitability without falling below the optimal visitor count\n",
    "#optimal_setup = max(simulation_results.items(), key=lambda x: x[1][1] if x[1][0] >= optimal_visitors_per_store else 0)\n",
    "\n",
    "# print(\"Optimal Number of Stores:\", optimal_setup[0])\n",
    "# print(\"Visitors per Store:\", optimal_setup[1][0])\n",
    "# print(\"Profitability (%):\", optimal_setup[1][1])\n",
    "\n",
    "simulation_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "34f350cd-2838-45fc-a0b3-a2a0d26e5789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Profit from Simulations: 1903086471.5260546\n",
      "Profit Standard Deviation: 2234144388.4179606\n"
     ]
    }
   ],
   "source": [
    "prob_matrix = np.array([\n",
    "    [0.999, 0.989, 0.966, 0.906, 0.717, 0.496, 0.236],\n",
    "    [0.999, 0.979, 0.941, 0.849, 0.610, 0.387, 0.172],\n",
    "    [0.997, 0.962, 0.899, 0.767, 0.490, 0.288, 0.123],\n",
    "    [0.995, 0.933, 0.834, 0.659, 0.372, 0.206, 0.086],\n",
    "    [0.989, 0.883, 0.739, 0.531, 0.268, 0.142, 0.060],\n",
    "    [0.978, 0.803, 0.615, 0.398, 0.184, 0.096, 0.041]\n",
    "])\n",
    "distances = np.array([0, 1, 2, 3, 4, 5])  # in miles\n",
    "densities = np.array([1, 5, 10, 20, 50, 100, 250])  # thousands of people within a 5-mile radius\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example usage of the class:\n",
    "model = NeighborhoodMarketExpansionModel(\n",
    "    demographic_data={},\n",
    "    market_conditions={\"cannibalization_rate\": 0.01, \"ecommerce_growth_factor\": 0.05},\n",
    "    financials={ \"base_operational_cost\": 20000, \"investment\": 100000},\n",
    "    investment_factors={},\n",
    "    historical_data={},\n",
    "    prob_matrix=prob_matrix,\n",
    "    densities=densities,\n",
    "    store_data = {\n",
    "    'Supercenters': {'locations': 3573, 'avg_sqft': 178000, 'density_eligibility': np.array([1, .8, .8, .8, 0.3, 0, 0])},\n",
    "    'Discount Stores': {'locations': 370, 'avg_sqft': 105000, 'density_eligibility': np.array([0, .2, .2, .2, 0, 0, 0])},\n",
    "    'Neighborhood Markets': {'locations': 799, 'avg_sqft': 42000, 'density_eligibility': np.array([0, 0, 0, 0, 0.7, 1, 1])}\n",
    "},\n",
    "    distances=distances,\n",
    "    avg_spending_per_visitor = {'Supercenters': 35.0, 'Discount Stores': 28.5, 'Neighborhood Markets': 32.0}\n",
    ")\n",
    "average_profit, profit_std_dev = model.run_monte_carlo_simulations()\n",
    "print(f\"Average Profit from Simulations: {average_profit}\")\n",
    "print(f\"Profit Standard Deviation: {profit_std_dev}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe07ee1f-a492-45bb-918a-57b0ca9e92fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e09e8c16-4c0a-4d8d-a88b-de4668ca7235",
   "metadata": {},
   "source": [
    "## Trying to workout expenses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b787958c-28a0-4cff-85de-f1672cd04bd8",
   "metadata": {},
   "source": [
    "## Additional insights from appendices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d92b80-4d1b-43d7-9076-b36a95e03d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WalmartFinancialModel:\n",
    "    # Existing methods...\n",
    "\n",
    "    def calculate_supply_chain_efficiencies(self, automation_investments, year):\n",
    "        # Estimate cost savings and revenue impacts from supply chain automation\n",
    "        savings = automation_investments * 0.05  # Assuming 5% cost saving from automation\n",
    "        additional_revenue = savings * 3  # Hypothetical multiplier for revenue from improved delivery speeds\n",
    "        return savings, additional_revenue\n",
    "    \n",
    "    def evaluate_membership_programs(self, subscribers, subscription_fee):\n",
    "        # Calculate revenue from subscription-based models like Walmart+\n",
    "        return subscribers * subscription_fee\n",
    "\n",
    "    def scenario_analysis(self, base_case_parameters, scenarios):\n",
    "        # Conduct scenario analysis based on varying parameters\n",
    "        results = {}\n",
    "        for scenario, params in scenarios.items():\n",
    "            self.update_market_conditions(params)  # Method to dynamically adjust market conditions\n",
    "            results[scenario] = self.run_financial_forecast()\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be59d47f-9977-463d-b340-dc864364866d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupplyChainModel:\n",
    "    def __init__(self, initial_investment, cost_savings_rate, revenue_growth_rate):\n",
    "        self.initial_investment = initial_investment\n",
    "        self.cost_savings_rate = cost_savings_rate  # Percentage of operational cost savings\n",
    "        self.revenue_growth_rate = revenue_growth_rate  # Additional revenue growth from enhanced capabilities\n",
    "\n",
    "    def calculate_cost_savings(self, operational_costs):\n",
    "        # Calculate cost savings based on the initial investment and operational cost savings rate\n",
    "        savings = operational_costs * self.cost_savings_rate\n",
    "        return savings\n",
    "\n",
    "    def calculate_revenue_growth(self, base_revenue):\n",
    "        # Calculate additional revenue generated from investments\n",
    "        additional_revenue = base_revenue * self.revenue_growth_rate\n",
    "        return additional_revenue\n",
    "\n",
    "    def simulate_financial_impact(self, operational_costs, base_revenue):\n",
    "        # Calculate both cost savings and additional revenue\n",
    "        savings = self.calculate_cost_savings(operational_costs)\n",
    "        additional_revenue = self.calculate_revenue_growth(base_revenue)\n",
    "        \n",
    "        # Net effect on operations\n",
    "        net_operational_costs = operational_costs - savings\n",
    "        net_revenue = base_revenue + additional_revenue\n",
    "\n",
    "        return net_operational_costs, net_revenue\n",
    "\n",
    "# Example usage\n",
    "initial_investment = 50000000  # $50 million\n",
    "operational_costs = 100000000  # $100 million annual operational costs\n",
    "base_revenue = 500000000  # $500 million base revenue\n",
    "\n",
    "supply_chain_model = SupplyChainModel(initial_investment, cost_savings_rate=0.1, revenue_growth_rate=0.05)\n",
    "net_costs, net_revenue = supply_chain_model.simulate_financial_impact(operational_costs, base_revenue)\n",
    "\n",
    "print(f\"Net Operational Costs after Savings: ${net_costs}\")\n",
    "print(f\"Net Revenue after Investment: ${net_revenue}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e16204-e0ea-4962-81f0-9e4081df8ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECommerceGrowth:\n",
    "    def __init__(self, base_sales, growth_rate, subscribers, subscription_fee, fulfillment_impact):\n",
    "        self.base_sales = base_sales\n",
    "        self.growth_rate = growth_rate\n",
    "        self.subscribers = subscribers\n",
    "        self.subscription_fee = subscription_fee\n",
    "        self.fulfillment_impact = fulfillment_impact\n",
    "\n",
    "    def calculate_incremental_revenue_from_subscriptions(self):\n",
    "        # Direct revenue from subscriptions\n",
    "        direct_revenue = self.subscribers * self.subscription_fee\n",
    "        \n",
    "        # Indirect revenue could be modeled based on increased purchase frequency\n",
    "        # Assuming a 5% increase in overall purchases due to membership benefits\n",
    "        indirect_revenue = self.base_sales * 0.05\n",
    "        return direct_revenue + indirect_revenue\n",
    "\n",
    "    def calculate_revenue_from_fulfillment_expansion(self):\n",
    "        # Additional revenue from enhanced fulfillment capabilities\n",
    "        # Assuming a 3% increase in sales due to better customer service and faster delivery\n",
    "        additional_revenue = self.base_sales * self.fulfillment_impact\n",
    "        return additional_revenue\n",
    "\n",
    "    def simulate_e_commerce_growth(self):\n",
    "        # Calculate total e-commerce growth including Walmart+ and fulfillment impacts\n",
    "        subscription_revenue = self.calculate_incremental_revenue_from_subscriptions()\n",
    "        fulfillment_revenue = self.calculate_revenue_from_fulfillment_expansion()\n",
    "        total_revenue = self.base_sales + subscription_revenue + fulfillment_revenue\n",
    "        return total_revenue\n",
    "\n",
    "# Example usage\n",
    "ecommerce_growth = ECommerceGrowth(base_sales=100000000, growth_rate=0.1, subscribers=1000000, subscription_fee=98, fulfillment_impact=0.03)\n",
    "total_revenue = ecommerce_growth.simulate_e_commerce_growth()\n",
    "\n",
    "print(f\"Total Projected E-Commerce Revenue: ${total_revenue}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd4ec3a-7b68-4e3b-97e6-89a4966d71cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the SupplyChainModel to focus exclusively on cost savings\n",
    "class SupplyChainModel:\n",
    "    def __init__(self, initial_investment, cost_savings_rate):\n",
    "        self.initial_investment = initial_investment\n",
    "        self.cost_savings_rate = cost_savings_rate  # Only focus on cost savings\n",
    "\n",
    "    def calculate_cost_savings(self, operational_costs):\n",
    "        # Calculate cost savings based on operational efficiencies\n",
    "        return operational_costs * self.cost_savings_rate\n",
    "\n",
    "# Redefine the ECommerceGrowth to explicitly cover all revenue impacts, removing generic revenue growth from supply chain improvements\n",
    "class ECommerceGrowth:\n",
    "    def __init__(self, base_sales, subscribers, subscription_fee, fulfillment_impact):\n",
    "        self.base_sales = base_sales\n",
    "        self.subscribers = subscribers\n",
    "        self.subscription_fee = subscription_fee\n",
    "        self.fulfillment_impact = fulfillment_impact  # Include all revenue enhancements from fulfillment\n",
    "\n",
    "    def simulate_e_commerce_growth(self):\n",
    "        # Calculate direct revenue from subscriptions\n",
    "        direct_revenue = self.subscribers * self.subscription_fee\n",
    "        # Revenue from enhanced fulfillment capabilities\n",
    "        additional_revenue = self.base_sales * (0.05 + self.fulfillment_impact)  # Include indirect revenue from subscriptions and fulfillment improvements\n",
    "        return self.base_sales + direct_revenue + additional_revenue\n",
    "\n",
    "# This adjustment ensures that the revenue from supply chain improvements is not double-counted with the fulfillment enhancements in ECommerceGrowth.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5128a6-81f0-4a49-b481-2bbdbadab433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class FinancialModel:\n",
    "    def __init__(self, base_sales, operational_costs, supply_chain_params, ecommerce_params):\n",
    "        self.base_sales = base_sales\n",
    "        self.operational_costs = operational_costs\n",
    "        self.supply_chain_model = SupplyChainModel(**supply_chain_params)\n",
    "        self.ecommerce_growth = ECommerceGrowth(**ecommerce_params)\n",
    "\n",
    "    def run_simulation(self, num_simulations=1000):\n",
    "        results = []\n",
    "        for _ in range(num_simulations):\n",
    "            # Randomly generate input parameters from assumed distributions\n",
    "            sampled_operational_costs = np.random.normal(self.operational_costs, self.operational_costs * 0.1)  # 10% SD\n",
    "            sampled_base_sales = np.random.normal(self.base_sales, self.base_sales * 0.1)  # 10% SD\n",
    "\n",
    "            # Calculate impacts from each model component\n",
    "            net_operational_costs = self.supply_chain_model.calculate_cost_savings(sampled_operational_costs)\n",
    "            net_revenue = self.ecommerce_growth.simulate_e_commerce_growth()\n",
    "\n",
    "            # Calculate net profit or other financial metrics\n",
    "            net_profit = net_revenue - net_operational_costs\n",
    "            results.append(net_profit)\n",
    "\n",
    "        return np.mean(results), np.std(results)  # Return average and standard deviation of results\n",
    "\n",
    "# Example usage with some hypothetical parameters\n",
    "params = {\n",
    "    'base_sales': 500000000,\n",
    "    'operational_costs': 100000000,\n",
    "    'supply_chain_params': {'initial_investment': 50000000, 'cost_savings_rate': 0.05},\n",
    "    'ecommerce_params': {'base_sales': 500000000, 'subscribers': 1000000, 'subscription_fee': 98, 'fulfillment_impact': 0.03}\n",
    "}\n",
    "model = FinancialModel(**params)\n",
    "average_profit, profit_std_dev = model.run_simulation(num_simulations=10000)\n",
    "\n",
    "print(f\"Average Projected Profit: ${average_profit:.2f}\")\n",
    "print(f\"Profit Standard Deviation: ${profit_std_dev:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed94500-96cb-4557-866b-245edce30faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StoreSpendingScaler:\n",
    "    def __init__(self, total_net_sales, total_annual_visits, square_footage, average_sqft):\n",
    "        self.total_net_sales = total_net_sales\n",
    "        self.total_annual_visits = total_annual_visits\n",
    "        self.square_footage = square_footage\n",
    "        self.average_sqft = average_sqft\n",
    "\n",
    "    def calculate_revenue_per_sqft(self):\n",
    "        revenue_per_sqft = {store_type: (self.total_net_sales * 1e6 / sqft)\n",
    "                            for store_type, sqft in self.square_footage.items()}\n",
    "        return revenue_per_sqft\n",
    "\n",
    "    def derive_scaling_factors(self):\n",
    "        min_avg_sqft = min(self.average_sqft.values())\n",
    "        scaling_factors = {store_type: min_avg_sqft / sqft\n",
    "                           for store_type, sqft in self.average_sqft.items()}\n",
    "        return scaling_factors\n",
    "\n",
    "    def calculate_adjusted_spending(self):\n",
    "        average_spending_per_visit = self.total_net_sales * 1e6 / self.total_annual_visits\n",
    "        scaling_factors = self.derive_scaling_factors()\n",
    "        adjusted_spending = {store_type: average_spending_per_visit * factor\n",
    "                             for store_type, factor in scaling_factors.items()}\n",
    "        return adjusted_spending\n",
    "\n",
    "    def summarize_spending_adjustments(self):\n",
    "        revenue_per_sqft = self.calculate_revenue_per_sqft()\n",
    "        adjusted_spending = self.calculate_adjusted_spending()\n",
    "\n",
    "        print(\"Revenue per Square Foot:\")\n",
    "        for store, revenue in revenue_per_sqft.items():\n",
    "            print(f\"{store}: ${revenue:.2f}\")\n",
    "\n",
    "        print(\"\\nAdjusted Average Spending per Customer per Store Type:\")\n",
    "        for store, spending in adjusted_spending.items():\n",
    "            print(f\"{store}: ${spending:.2f} per visit\")\n",
    "\n",
    "# Example usage\n",
    "store_data = {\n",
    "    'total_net_sales': 393247,  # in millions of dollars\n",
    "    'total_annual_visits': 11960 * 1e6,  # converting to total visits per year\n",
    "    'square_footage': {\n",
    "        'Supercenters': 634192948,\n",
    "        'Discount Stores': 39198914,\n",
    "        'Neighborhood Markets': 29036713\n",
    "    },\n",
    "    'average_sqft': {\n",
    "        'Supercenters': 178000,\n",
    "        'Discount Stores': 105000,\n",
    "        'Neighborhood Markets': 42000\n",
    "    }\n",
    "}\n",
    "\n",
    "scaler = StoreSpendingScaler(**store_data)\n",
    "scaler.summarize_spending_adjustments()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

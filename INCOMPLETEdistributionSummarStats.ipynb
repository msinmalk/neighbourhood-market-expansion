{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3f27ca-922b-4183-b81d-465744b288f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all sheets from the Excel file to examine and clean them\n",
    "all_sheets = pd.read_excel(file_path, sheet_name=None)  # None loads all sheets\n",
    "\n",
    "# Dictionary to store cleaned data from all sheets\n",
    "cleaned_sheets = {}\n",
    "\n",
    "# Function to clean each sheet similar to previous methods\n",
    "def clean_sheet(data):\n",
    "    # Initializing temporary and permanent storage structures\n",
    "    cleaned_data = {\n",
    "        'State': [],\n",
    "        'DC Number': [],\n",
    "        'Location': [],\n",
    "        'Square Feet': [],\n",
    "        'Year Opened': [],\n",
    "        'Description of Operation': []\n",
    "    }\n",
    "    temp_location = ''\n",
    "    temp_description = ''\n",
    "    temp_year = None\n",
    "\n",
    "    # Iterate through the rows of the data\n",
    "    for index, row in data.iterrows():\n",
    "        if pd.notna(row['State']):  # Start of a new entry\n",
    "            if temp_location:\n",
    "                cleaned_data['Location'].append(temp_location)\n",
    "                cleaned_data['Description of Operation'].append(temp_description)\n",
    "                cleaned_data['Year Opened'].append(temp_year)\n",
    "            temp_location = ''\n",
    "            temp_description = ''\n",
    "            temp_year = None\n",
    "            \n",
    "            cleaned_data['State'].append(row['State'])\n",
    "            cleaned_data['DC Number'].append(row['DC'])\n",
    "            temp_location = str(row['Location']) if pd.notna(row['Location']) else ''\n",
    "            cleaned_data['Square Feet'].append(row['Square Feet'] if pd.notna(row['Square Feet']) else None)\n",
    "            temp_year = row['Year'] if pd.notna(row['Year']) else None\n",
    "            temp_description = row['Description of Operation'] if pd.notna(row['Description of Operation']) else ''\n",
    "        else:\n",
    "            if pd.notna(row['Location']):\n",
    "                temp_location += ' ' + str(row['Location'])\n",
    "            if pd.notna(row['Description of Operation']):\n",
    "                temp_description += ' ' + row['Description of Operation']\n",
    "    \n",
    "    if temp_location:\n",
    "        cleaned_data['Location'].append(temp_location)\n",
    "        cleaned_data['Description of Operation'].append(temp_description)\n",
    "        cleaned_data['Year Opened'].append(temp_year)\n",
    "\n",
    "    return pd.DataFrame(cleaned_data)\n",
    "\n",
    "# Process each sheet\n",
    "for sheet_name, data in all_sheets.items():\n",
    "    cleaned_sheets[sheet_name] = clean_sheet(data)\n",
    "\n",
    "# Now, cleaned_sheets contains all the cleaned data indexed by sheet names\n",
    "len(cleaned_sheets)  # Display the count of cleaned sheets to ensure all are processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d165871e-77cf-4e50-8284-27de95c2b533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check column headers for each sheet to identify discrepancies\n",
    "column_headers = {sheet_name: data.columns.tolist() for sheet_name, data in all_sheets.items()}\n",
    "column_headers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bf1d59-b7db-4ae8-af68-5b4fa22b6ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize column names and proceed with data cleaning for each sheet\n",
    "def standardize_columns(data):\n",
    "    # Standardize column names to match the most common format\n",
    "    data = data.rename(columns={\n",
    "        'DC Number': 'DC',\n",
    "        'Year Opened': 'Year',\n",
    "        'Unnamed: 6': 'Extra'  # Handle any extra unnamed columns that appear\n",
    "    })\n",
    "    return data\n",
    "\n",
    "# Re-process each sheet with standardized columns\n",
    "for sheet_name, data in all_sheets.items():\n",
    "    standardized_data = standardize_columns(data)\n",
    "    cleaned_sheets[sheet_name] = clean_sheet(standardized_data)\n",
    "\n",
    "# Now, cleaned_sheets contains all the cleaned data indexed by sheet names\n",
    "len(cleaned_sheets)  # Display the count of cleaned sheets to ensure all are processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f02eea-1087-4ee3-808f-b5e6e7fc6720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refine the cleaning process to handle incomplete or improperly accumulated data\n",
    "\n",
    "def refined_clean_sheet(data):\n",
    "    # Initializing temporary and permanent storage structures\n",
    "    cleaned_data = {\n",
    "        'State': [],\n",
    "        'DC': [],\n",
    "        'Location': [],\n",
    "        'Square Feet': [],\n",
    "        'Year': [],\n",
    "        'Description of Operation': []\n",
    "    }\n",
    "    temp_location = ''\n",
    "    temp_description = ''\n",
    "    temp_year = None\n",
    "    temp_square_feet = None\n",
    "\n",
    "    # Iterate through the rows of the data\n",
    "    for index, row in data.iterrows():\n",
    "        if pd.notna(row['State']):  # Start of a new entry\n",
    "            if temp_location:\n",
    "                cleaned_data['Location'].append(temp_location)\n",
    "                cleaned_data['Description of Operation'].append(temp_description)\n",
    "                cleaned_data['Year'].append(temp_year)\n",
    "                cleaned_data['Square Feet'].append(temp_square_feet)\n",
    "            temp_location = ''\n",
    "            temp_description = ''\n",
    "            temp_year = None\n",
    "            temp_square_feet = None\n",
    "            \n",
    "            cleaned_data['State'].append(row['State'])\n",
    "            cleaned_data['DC'].append(row['DC'])\n",
    "            temp_location = str(row['Location']) if pd.notna(row['Location']) else ''\n",
    "            temp_square_feet = row['Square Feet'] if pd.notna(row['Square Feet']) else None\n",
    "            temp_year = row['Year'] if pd.notna(row['Year']) else None\n",
    "            temp_description = row['Description of Operation'] if pd.notna(row['Description of Operation']) else ''\n",
    "        else:\n",
    "            if pd.notna(row['Location']):\n",
    "                temp_location += ' ' + str(row['Location'])\n",
    "            if pd.notna(row['Description of Operation']):\n",
    "                temp_description += ' ' + row['Description of Operation']\n",
    "\n",
    "    # Append the last entry\n",
    "    if temp_location:\n",
    "        cleaned_data['Location'].append(temp_location)\n",
    "        cleaned_data['Description of Operation'].append(temp_description)\n",
    "        cleaned_data['Year'].append(temp_year)\n",
    "        cleaned_data['Square Feet'].append(temp_square_feet)\n",
    "\n",
    "    return pd.DataFrame(cleaned_data)\n",
    "\n",
    "# Re-process each sheet with refined cleaning process\n",
    "for sheet_name, data in all_sheets.items():\n",
    "    standardized_data = standardize_columns(data)\n",
    "    cleaned_sheets[sheet_name] = refined_clean_sheet(standardized_data)\n",
    "\n",
    "# Check the count of cleaned sheets to ensure all are processed\n",
    "len(cleaned_sheets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92105569-bd6a-470d-8240-a99021cc004d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing a more robust check to ensure all fields are populated in each row\n",
    "\n",
    "def fully_refined_clean_sheet(data):\n",
    "    # Initializing temporary and permanent storage structures\n",
    "    cleaned_data = {\n",
    "        'State': [],\n",
    "        'DC': [],\n",
    "        'Location': [],\n",
    "        'Square Feet': [],\n",
    "        'Year': [],\n",
    "        'Description of Operation': []\n",
    "    }\n",
    "    temp_location = ''\n",
    "    temp_description = ''\n",
    "    temp_year = None\n",
    "    temp_square_feet = None\n",
    "    entry_complete = True\n",
    "\n",
    "    # Iterate through the rows of the data\n",
    "    for index, row in data.iterrows():\n",
    "        if pd.notna(row['State']) and entry_complete:  # Start of a new entry\n",
    "            if temp_location:\n",
    "                cleaned_data['Location'].append(temp_location)\n",
    "                cleaned_data['Description of Operation'].append(temp_description)\n",
    "                cleaned_data['Year'].append(temp_year)\n",
    "                cleaned_data['Square Feet'].append(temp_square_feet)\n",
    "            temp_location = ''\n",
    "            temp_description = ''\n",
    "            temp_year = None\n",
    "            temp_square_feet = None\n",
    "            entry_complete = False\n",
    "            \n",
    "            cleaned_data['State'].append(row['State'])\n",
    "            cleaned_data['DC'].append(row['DC'])\n",
    "            temp_location = str(row['Location']) if pd.notna(row['Location']) else ''\n",
    "            temp_square_feet = row['Square Feet'] if pd.notna(row['Square Feet']) else None\n",
    "            temp_year = row['Year'] if pd.notna(row['Year']) else None\n",
    "            temp_description = row['Description of Operation'] if pd.notna(row['Description of Operation']) else ''\n",
    "        else:\n",
    "            if pd.notna(row['Location']):\n",
    "                temp_location += ' ' + str(row['Location'])\n",
    "            if pd.notna(row['Description of Operation']):\n",
    "                temp_description += ' ' + row['Description of Operation']\n",
    "            if pd.notna(row['Year']):\n",
    "                temp_year = row['Year']\n",
    "            if pd.notna(row['Square Feet']):\n",
    "                temp_square_feet = row['Square Feet']\n",
    "            entry_complete = True\n",
    "\n",
    "    # Append the last entry\n",
    "    if temp_location:\n",
    "        cleaned_data['Location'].append(temp_location)\n",
    "        cleaned_data['Description of Operation'].append(temp_description)\n",
    "        cleaned_data['Year'].append(temp_year)\n",
    "        cleaned_data['Square Feet'].append(temp_square_feet)\n",
    "\n",
    "    return pd.DataFrame(cleaned_data)\n",
    "\n",
    "# Re-process each sheet with fully refined cleaning process\n",
    "for sheet_name, data in all_sheets.items():\n",
    "    standardized_data = standardize_columns(data)\n",
    "    cleaned_sheets[sheet_name] = fully_refined_clean_sheet(standardized_data)\n",
    "\n",
    "# Check the count of cleaned sheets to ensure all are processed\n",
    "len(cleaned_sheets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8502981e-d957-4b19-ab13-f9808f9a5502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified cleaning approach to extract only necessary data for summary statistics\n",
    "def simplified_clean_sheet(data):\n",
    "    cleaned_entries = {\n",
    "        'Year': [],\n",
    "        'Square Feet': []\n",
    "    }\n",
    "    \n",
    "    for index, row in data.iterrows():\n",
    "        # Checking for complete entries directly based on essential data presence\n",
    "        if pd.notna(row['State']) and pd.notna(row['Square Feet']) and pd.notna(row['Year']):\n",
    "            # Extract only the year portion if it contains more detail\n",
    "            year = str(row['Year']).split(\",\")[-1].strip()\n",
    "            cleaned_entries['Year'].append(year)\n",
    "            cleaned_entries['Square Feet'].append(row['Square Feet'])\n",
    "    \n",
    "    return pd.DataFrame(cleaned_entries)\n",
    "\n",
    "# Applying the simplified cleaning method\n",
    "simplified_cleaned_data = {}\n",
    "for sheet_name, data in all_sheets.items():\n",
    "    standardized_data = standardize_columns(data)\n",
    "    simplified_cleaned_data[sheet_name] = simplified_clean_sheet(standardized_data)\n",
    "\n",
    "# Check the number of entries processed to ensure data was collected\n",
    "{sheet: len(df) for sheet, df in simplified_cleaned_data.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f457f9eb-52e7-4713-bc78-d0bc1b03feee",
   "metadata": {},
   "source": [
    "## Second GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098f5787-efb5-4554-abd4-bae4b756dd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load all sheets from the uploaded Excel file\n",
    "file_path = '/mnt/data/Distribution Centers.xlsx'\n",
    "all_sheets = pd.read_excel(file_path, sheet_name=None)\n",
    "\n",
    "def clean_sheet(data):\n",
    "    cleaned_data = {\n",
    "        'State': [],\n",
    "        'DC Number': [],\n",
    "        'Location': [],\n",
    "        'Square Feet': [],\n",
    "        'Year Opened': [],\n",
    "        'Description of Operation': []\n",
    "    }\n",
    "    temp_storage = {}\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        if pd.notna(row['State']):  # Indicates the start of a new entry\n",
    "            if temp_storage:  # There is previous data to append\n",
    "                for key in cleaned_data:\n",
    "                    cleaned_data[key].append(temp_storage.get(key, ''))\n",
    "                temp_storage = {}\n",
    "            # Update temporary storage with new data\n",
    "            temp_storage = {\n",
    "                'State': row.get('State', ''),\n",
    "                'DC Number': row.get('DC Number', ''),\n",
    "                'Location': row.get('Location', ''),\n",
    "                'Square Feet': row.get('Square Feet', None),\n",
    "                'Year Opened': row.get('Year Opened', None),\n",
    "                'Description of Operation': row.get('Description of Operation', '')\n",
    "            }\n",
    "        else:\n",
    "            # Continuation of existing entry, append additional info\n",
    "            temp_storage['Location'] = temp_storage.get('Location', '') + ' ' + str(row.get('Location', ''))\n",
    "            temp_storage['Description of Operation'] = temp_storage.get('Description of Operation', '') + ' ' + str(row.get('Description of Operation', ''))\n",
    "\n",
    "    # Append the last collected entry\n",
    "    if temp_storage:\n",
    "        for key in cleaned_data:\n",
    "            cleaned_data[key].append(temp_storage.get(key, ''))\n",
    "\n",
    "    return pd.DataFrame(cleaned_data)\n",
    "\n",
    "def standardize_columns(data):\n",
    "    # Define a dictionary to map actual column names to standardized ones\n",
    "    standard_names = {\n",
    "        'DC': 'DC Number',\n",
    "        'Year': 'Year Opened',\n",
    "        # Add all known variations here\n",
    "    }\n",
    "    # Check if column names in data are in the keys of standard_names, if so, rename them\n",
    "    data = data.rename(columns={old: standard_names.get(old, old) for old in data.columns})\n",
    "    return data\n",
    "\n",
    "# Cleaning all sheets\n",
    "cleaned_sheets = {}\n",
    "for sheet_name, data in all_sheets.items():\n",
    "    data = standardize_columns(data)  # Standardize columns first\n",
    "    cleaned_sheets[sheet_name] = clean_sheet(data)  # Clean data\n",
    "\n",
    "# Display the count of cleaned sheets and a preview to ensure all are processed\n",
    "print(\"Total sheets cleaned:\", len(cleaned_sheets))\n",
    "for name, sheet in cleaned_sheets.items():\n",
    "    print(f\"Preview of {name}:\")\n",
    "    print(sheet.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e19a1fc-dc33-4f5e-a0e1-3ae51bed89da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated and corrected version of the script to handle the mismatch in column names and prevent KeyError\n",
    "\n",
    "def clean_sheet(data):\n",
    "    cleaned_data = {\n",
    "        'State': [],\n",
    "        'DC Number': [],\n",
    "        'Location': [],\n",
    "        'Square Feet': [],\n",
    "        'Year Opened': [],\n",
    "        'Description of Operation': []\n",
    "    }\n",
    "    temp_storage = {}\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        if pd.notna(row['State']):  # Indicates the start of a new entry\n",
    "            if temp_storage:  # There is previous data to append\n",
    "                for key in cleaned_data:\n",
    "                    cleaned_data[key].append(temp_storage.get(key, ''))\n",
    "                temp_storage = {}\n",
    "            # Update temporary storage with new data\n",
    "            temp_storage = {\n",
    "                'State': row.get('State', ''),\n",
    "                'DC Number': row.get('DC Number', ''),\n",
    "                'Location': row.get('Location', ''),\n",
    "                'Square Feet': row.get('Square Feet', None),\n",
    "                'Year Opened': row.get('Year Opened', None),\n",
    "                'Description of Operation': row.get('Description of Operation', '')\n",
    "            }\n",
    "        else:\n",
    "            # Continuation of existing entry, append additional info\n",
    "            temp_storage['Location'] = temp_storage.get('Location', '') + ' ' + str(row.get('Location', ''))\n",
    "            temp_storage['Description of Operation'] = temp_storage.get('Description of Operation', '') + ' ' + str(row.get('Description of Operation', ''))\n",
    "\n",
    "    # Append the last collected entry\n",
    "    if temp_storage:\n",
    "        for key in cleaned_data:\n",
    "            cleaned_data[key].append(temp_storage.get(key, ''))\n",
    "\n",
    "    return pd.DataFrame(cleaned_data)\n",
    "\n",
    "def standardize_columns(data):\n",
    "    # Define a dictionary to map actual column names to standardized ones\n",
    "    standard_names = {\n",
    "        'DC': 'DC Number',\n",
    "        'Year': 'Year Opened',\n",
    "        # Ensure all variations are covered\n",
    "    }\n",
    "    # Check if column names in data are in the keys of standard_names, if so, rename them\n",
    "    data = data.rename(columns={old: standard_names.get(old, old) for old in data.columns})\n",
    "    return data\n",
    "\n",
    "# Cleaning all sheets\n",
    "cleaned_sheets = {}\n",
    "for sheet_name, data in all_sheets.items():\n",
    "    data = standardize_columns(data)  # Standardize columns first\n",
    "    cleaned_sheets[sheet_name] = clean_sheet(data)  # Clean data\n",
    "\n",
    "# Display the count of cleaned sheets and a preview to ensure all are processed\n",
    "len(cleaned_sheets), {sheet_name: sheet_data.head() for sheet_name, sheet_data in cleaned_sheets.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec83b69-20c7-461e-b49d-4b2eccc8b476",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_storage['Location'] = temp_storage.get('Location', '') + ' ' + str(row.get('Location', '') if pd.notna(row['Location']) else '')\n",
    "temp_storage['Description of Operation'] = temp_storage.get('Description of Operation', '') + ' ' + str(row.get('Description of Operation', '') if pd.notna(row['Description of Operation']) else '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2e42cf-3c7b-4acc-a753-763ddf973ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated version of the script to handle concatenation of strings and floats correctly\n",
    "\n",
    "def clean_sheet(data):\n",
    "    cleaned_data = {\n",
    "        'State': [],\n",
    "        'DC Number': [],\n",
    "        'Location': [],\n",
    "        'Square Feet': [],\n",
    "        'Year Opened': [],\n",
    "        'Description of Operation': []\n",
    "    }\n",
    "    temp_storage = {}\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        if pd.notna(row['State']):  # Indicates the start of a new entry\n",
    "            if temp_storage:  # There is previous data to append\n",
    "                for key in cleaned_data:\n",
    "                    cleaned_data[key].append(temp_storage.get(key, ''))\n",
    "                temp_storage = {}\n",
    "            # Update temporary storage with new data\n",
    "            temp_storage = {\n",
    "                'State': row.get('State', ''),\n",
    "                'DC Number': row.get('DC Number', ''),\n",
    "                'Location': row.get('Location', ''),\n",
    "                'Square Feet': row.get('Square Feet', None),\n",
    "                'Year Opened': row.get('Year Opened', None),\n",
    "                'Description of Operation': row.get('Description of Operation', '')\n",
    "            }\n",
    "        else:\n",
    "            # Continuation of existing entry, append additional info\n",
    "            temp_storage['Location'] = temp_storage.get('Location', '') + ' ' + (str(row['Location']) if pd.notna(row['Location']) else '')\n",
    "            temp_storage['Description of Operation'] = temp_storage.get('Description of Operation', '') + ' ' + (str(row['Description of Operation']) if pd.notna(row['Description of Operation']) else '')\n",
    "\n",
    "    # Append the last collected entry\n",
    "    if temp_storage:\n",
    "        for key in cleaned_data:\n",
    "            cleaned_data[key].append(temp_storage.get(key, ''))\n",
    "\n",
    "    return pd.DataFrame(cleaned_data)\n",
    "\n",
    "# Cleaning all sheets\n",
    "cleaned_sheets = {}\n",
    "for sheet_name, data in all_sheets.items():\n",
    "    data = standardize_columns(data)  # Standardize columns first\n",
    "    cleaned_sheets[sheet_name] = clean_sheet(data)  # Clean data\n",
    "\n",
    "# Display the count of cleaned sheets and a preview to ensure all are processed\n",
    "len(cleaned_sheets), {sheet_name: sheet_data.head() for sheet_name, sheet_data in cleaned_sheets.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade94060-04db-42a5-aea8-f5905a2f8e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    " temp_storage['Location'] = temp_storage.get('Location', '') + ' ' + (str(row['Location']) if pd.notna(row['Location']) else '')\n",
    "temp_storage['Description of Operation'] = temp_storage.get('Description of Operation', '') + ' ' + (str(row['Description of Operation']) if pd.notna(row['Description of Operation']) else '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27774dab-fa2c-42fa-96db-7899cec06a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sheet(data):\n",
    "    cleaned_data = {\n",
    "        'State': [],\n",
    "        'DC Number': [],\n",
    "        'Location': [],\n",
    "        'Square Feet': [],\n",
    "        'Year Opened': [],\n",
    "        'Description of Operation': []\n",
    "    }\n",
    "    temp_storage = {}\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        if pd.notna(row['State']):  # Indicates the start of a new entry\n",
    "            if temp_storage:  # There is previous data to append\n",
    "                for key in cleaned_data:\n",
    "                    cleaned_data[key].append(temp_storage.get(key, ''))\n",
    "                temp_storage = {}\n",
    "            # Update temporary storage with new data\n",
    "            temp_storage = {\n",
    "                'State': str(row['State']),\n",
    "                'DC Number': str(row['DC Number']),\n",
    "                'Location': str(row['Location']) if pd.notna(row['Location']) else '',\n",
    "                'Square Feet': row['Square Feet'] if pd.notna(row['Square Feet']) else None,\n",
    "                'Year Opened': row['Year Opened'] if pd.notna(row['Year Opened']) else None,\n",
    "                'Description of Operation': str(row['Description of Operation']) if pd.notna(row['Description of Operation']) else ''\n",
    "            }\n",
    "        else:\n",
    "            # Continuation of existing entry, append additional info\n",
    "            temp_storage['Location'] += ' ' + (str(row['Location']) if pd.notna(row['Location']) else '')\n",
    "            temp_storage['Description of Operation'] += ' ' + (str(row['Description of Operation']) if pd.notna(row['Description of Operation']) else '')\n",
    "\n",
    "    # Append the last collected entry\n",
    "    if temp_storage:\n",
    "        for key in cleaned_data:\n",
    "            cleaned_data[key].append(temp_storage.get(key, ''))\n",
    "\n",
    "    return pd.DataFrame(cleaned_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60caf4c-5c4e-457b-a404-8ebb0590400c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the corrected clean_sheet function that handles data concatenation safely\n",
    "\n",
    "def clean_sheet(data):\n",
    "    cleaned_data = {\n",
    "        'State': [],\n",
    "        'DC Number': [],\n",
    "        'Location': [],\n",
    "        'Square Feet': [],\n",
    "        'Year Opened': [],\n",
    "        'Description of Operation': []\n",
    "    }\n",
    "    temp_storage = {}\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        if pd.notna(row['State']):  # Indicates the start of a new entry\n",
    "            if temp_storage:  # There is previous data to append\n",
    "                for key in cleaned_data:\n",
    "                    cleaned_data[key].append(temp_storage.get(key, ''))\n",
    "                temp_storage = {}\n",
    "            # Update temporary storage with new data\n",
    "            temp_storage = {\n",
    "                'State': str(row['State']),\n",
    "                'DC Number': str(row['DC Number']),\n",
    "                'Location': str(row['Location']) if pd.notna(row['Location']) else '',\n",
    "                'Square Feet': row['Square Feet'] if pd.notna(row['Square Feet']) else None,\n",
    "                'Year Opened': row['Year Opened'] if pd.notna(row['Year Opened']) else None,\n",
    "                'Description of Operation': str(row['Description of Operation']) if pd.notna(row['Description of Operation']) else ''\n",
    "            }\n",
    "        else:\n",
    "            # Continuation of existing entry, append additional info\n",
    "            temp_storage['Location'] += ' ' + (str(row['Location']) if pd.notna(row['Location']) else '')\n",
    "            temp_storage['Description of Operation'] += ' ' + (str(row['Description of Operation']) if pd.notna(row['Description of Operation']) else '')\n",
    "\n",
    "    # Append the last collected entry\n",
    "    if temp_storage:\n",
    "        for key in cleaned_data:\n",
    "            cleaned_data[key].append(temp_storage.get(key, ''))\n",
    "\n",
    "    return pd.DataFrame(cleaned_data)\n",
    "\n",
    "# Cleaning all sheets\n",
    "cleaned_sheets = {}\n",
    "for sheet_name, data in all_sheets.items():\n",
    "    data = standardize_columns(data)  # Standardize columns first\n",
    "    cleaned_sheets[sheet_name] = clean_sheet(data)  # Clean data\n",
    "\n",
    "# Display the count of cleaned sheets and a preview to ensure all are processed\n",
    "len(cleaned_sheets), {sheet_name: sheet_data.head() for sheet_name, sheet_data in cleaned_sheets.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca4ddfb-0bb1-4499-bd0e-3fd1abfa7dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sheet(data):\n",
    "    cleaned_data = {\n",
    "        'State': [],\n",
    "        'DC Number': [],\n",
    "        'Location': [],\n",
    "        'Square Feet': [],\n",
    "        'Year Opened': [],\n",
    "        'Description of Operation': []\n",
    "    }\n",
    "    # Initialize temp_storage with empty or default values for all keys\n",
    "    temp_storage = {key: '' if key in ['State', 'DC Number', 'Location', 'Description of Operation'] else None for key in cleaned_data}\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        if pd.notna(row['State']):  # Indicates the start of a new entry\n",
    "            if any(temp_storage.values()):  # There is previous data to append\n",
    "                for key in cleaned_data:\n",
    "                    cleaned_data[key].append(temp_storage.get(key, ''))\n",
    "                temp_storage = {key: '' if key in ['State', 'DC Number', 'Location', 'Description of Operation'] else None for key in cleaned_data}\n",
    "            \n",
    "            # Update temporary storage with new data\n",
    "            temp_storage.update({\n",
    "                'State': str(row['State']),\n",
    "                'DC Number': str(row['DC Number']),\n",
    "                'Location': str(row['Location']) if pd.notna(row['Location']) else '',\n",
    "                'Square Feet': row['Square Feet'] if pd.notna(row['Square Feet']) else None,\n",
    "                'Year Opened': row['Year Opened'] if pd.notna(row['Year Opened']) else None,\n",
    "                'Description of Operation': str(row['Description of Operation']) if pd.notna(row['Description of Operation']) else ''\n",
    "            })\n",
    "        else:\n",
    "            # Continuation of existing entry, append additional info\n",
    "            temp_storage['Location'] += ' ' + (str(row['Location']) if pd.notna(row['Location']) else '')\n",
    "            temp_storage['Description of Operation'] += ' ' + (str(row['Description of Operation']) if pd.notna(row['Description of Operation']) else '')\n",
    "\n",
    "    # Append the last collected entry\n",
    "    if any(temp_storage.values()):\n",
    "        for key in cleaned_data:\n",
    "            cleaned_data[key].append(temp_storage.get(key, ''))\n",
    "\n",
    "    return pd.DataFrame(cleaned_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04945f2e-da56-4b9e-8ab3-5572426177c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revised clean_sheet function with proper initialization of temp_storage to prevent KeyError\n",
    "\n",
    "def clean_sheet(data):\n",
    "    cleaned_data = {\n",
    "        'State': [],\n",
    "        'DC Number': [],\n",
    "        'Location': [],\n",
    "        'Square Feet': [],\n",
    "        'Year Opened': [],\n",
    "        'Description of Operation': []\n",
    "    }\n",
    "    # Initialize temp_storage with empty or default values for all keys\n",
    "    temp_storage = {key: '' if key in ['State', 'DC Number', 'Location', 'Description of Operation'] else None for key in cleaned_data}\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        if pd.notna(row['State']):  # Indicates the start of a new entry\n",
    "            if any(temp_storage.values()):  # There is previous data to append\n",
    "                for key in cleaned_data:\n",
    "                    cleaned_data[key].append(temp_storage.get(key, ''))\n",
    "                temp_storage = {key: '' if key in ['State', 'DC Number', 'Location', 'Description of Operation'] else None for key in cleaned_data}\n",
    "            \n",
    "            # Update temporary storage with new data\n",
    "            temp_storage.update({\n",
    "                'State': str(row['State']),\n",
    "                'DC Number': str(row['DC Number']),\n",
    "                'Location': str(row['Location']) if pd.notna(row['Location']) else '',\n",
    "                'Square Feet': row['Square Feet'] if pd.notna(row['Square Feet']) else None,\n",
    "                'Year Opened': row['Year Opened'] if pd.notna(row['Year Opened']) else None,\n",
    "                'Description of Operation': str(row['Description of Operation']) if pd.notna(row['Description of Operation']) else ''\n",
    "            })\n",
    "        else:\n",
    "            # Continuation of existing entry, append additional info\n",
    "            temp_storage['Location'] += ' ' + (str(row['Location']) if pd.notna(row['Location']) else '')\n",
    "            temp_storage['Description of Operation'] += ' ' + (str(row['Description of Operation']) if pd.notna(row['Description of Operation']) else '')\n",
    "\n",
    "    # Append the last collected entry\n",
    "    if any(temp_storage.values()):\n",
    "        for key in cleaned_data:\n",
    "            cleaned_data[key].append(temp_storage.get(key, ''))\n",
    "\n",
    "    return pd.DataFrame(cleaned_data)\n",
    "\n",
    "# Cleaning all sheets again with the revised function\n",
    "cleaned_sheets = {}\n",
    "for sheet_name, data in all_sheets.items():\n",
    "    data = standardize_columns(data)  # Standardize columns first\n",
    "    cleaned_sheets[sheet_name] = clean_sheet(data)  # Clean data\n",
    "\n",
    "# Display the count of cleaned sheets and a preview to ensure all are processed\n",
    "len(cleaned_sheets), {sheet_name: sheet_data.head() for sheet_name, sheet_data in cleaned_sheets.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f50caf-a801-470d-bbd4-389e50fcea39",
   "metadata": {},
   "source": [
    "## Summary Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dbd8f4-da5f-4deb-8ca5-c0be40320c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function to extract year from various date formats in the 'Year Opened' field\n",
    "def extract_year(date_str):\n",
    "    if pd.isna(date_str):\n",
    "        return None\n",
    "    match = re.search(r'\\b(19|20)\\d{2}\\b', str(date_str))\n",
    "    return int(match.group(0)) if match else None\n",
    "\n",
    "# Function to derive type from 'Description of Operation'\n",
    "def extract_type(description):\n",
    "    if \"Crossdock\" in description:\n",
    "        return \"Crossdock\"\n",
    "    elif \"Import\" in description:\n",
    "        return \"Import\"\n",
    "    elif \"Distribution Center\" in description:\n",
    "        return \"Distribution Center\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "# Prepare data for aggregation\n",
    "aggregated_data = {\n",
    "    'Year': [],\n",
    "    'Type': [],\n",
    "    'Square Feet': [],\n",
    "    'Count': []  # This will count the number of entries for DCs\n",
    "}\n",
    "\n",
    "for sheet_name, data in cleaned_sheets.items():\n",
    "    for index, row in data.iterrows():\n",
    "        year = extract_year(row['Year Opened'])\n",
    "        if year:  # Only process entries with a valid year\n",
    "            type_ = extract_type(row['Description of Operation'])\n",
    "            aggregated_data['Year'].append(year)\n",
    "            aggregated_data['Type'].append(type_)\n",
    "            aggregated_data['Square Feet'].append(row['Square Feet'] if pd.notna(row['Square Feet']) else 0)\n",
    "            aggregated_data['Count'].append(1)  # Each row counts as one DC\n",
    "\n",
    "# Convert aggregated data to DataFrame\n",
    "aggregated_df = pd.DataFrame(aggregated_data)\n",
    "\n",
    "# Summarize data: Total square feet and count of DCs by year and type\n",
    "summary_stats = aggregated_df.groupby(['Year', 'Type']).agg({'Square Feet': 'sum', 'Count': 'sum'}).reset_index()\n",
    "summary_stats.sort_values(by='Year', inplace=True)\n",
    "summary_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747d5687-4c2f-4256-a406-fbed6631540c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'Square Feet' is treated as floats and handle NaN values properly before aggregation\n",
    "\n",
    "# Convert 'Square Feet' to floats and replace NaN with 0 for aggregation\n",
    "aggregated_df['Square Feet'] = aggregated_df['Square Feet'].apply(lambda x: float(x) if pd.notna(x) else 0.0)\n",
    "\n",
    "# Summarize data: Total square feet and count of DCs by year and type\n",
    "summary_stats = aggregated_df.groupby(['Year', 'Type']).agg({'Square Feet': 'sum', 'Count': 'sum'}).reset_index()\n",
    "summary_stats.sort_values(by='Year', inplace=True)\n",
    "summary_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702beed9-5ff3-4218-9ad1-55cf8c740ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean 'Square Feet' by removing commas and converting to float\n",
    "aggregated_df['Square Feet'] = aggregated_df['Square Feet'].apply(lambda x: float(str(x).replace(',', '')) if pd.notna(x) else 0.0)\n",
    "\n",
    "# Summarize data: Total square feet and count of DCs by year and type\n",
    "summary_stats = aggregated_df.groupby(['Year', 'Type']).agg({'Square Feet': 'sum', 'Count': 'sum'}).reset_index()\n",
    "summary_stats.sort_values(by='Year', inplace=True)\n",
    "summary_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2996b514-fd14-4bf7-843b-8f8dd3787424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display unique values in 'Square Feet' that may be causing conversion problems\n",
    "unique_square_feet = set(aggregated_df['Square Feet'])\n",
    "unique_square_feet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2090028f-0483-420a-a4ad-9e05d44c9391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean and convert square feet values to floats\n",
    "def clean_square_feet(value):\n",
    "    if pd.isna(value):\n",
    "        return 0.0\n",
    "    # Remove commas, extract the first sequence of numbers possibly containing a dot\n",
    "    cleaned_value = re.findall(r'[\\d\\.]+', str(value).replace(',', '').replace(' ', ''))\n",
    "    return float(cleaned_value[0]) if cleaned_value else 0.0\n",
    "\n",
    "# Apply the cleaning function to the 'Square Feet' column\n",
    "aggregated_df['Square Feet'] = aggregated_df['Square Feet'].apply(clean_square_feet)\n",
    "\n",
    "# Summarize data: Total square feet and count of DCs by year and type\n",
    "summary_stats = aggregated_df.groupby(['Year', 'Type']).agg({'Square Feet': 'sum', 'Count': 'sum'}).reset_index()\n",
    "summary_stats.sort_values(by='Year', inplace=True)\n",
    "summary_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef057f99-54e1-47c6-8511-dd513e7f25f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_square_feet(value):\n",
    "    if pd.isna(value):\n",
    "        return 0.0\n",
    "    # Normalize the string by removing commas and extra spaces\n",
    "    value = str(value).replace(',', '').replace(' ', '')\n",
    "    # Handle cases with multiple periods\n",
    "    parts = value.split('.')\n",
    "    if len(parts) > 2:\n",
    "        value = ''.join(parts[:-1]) + '.' + parts[-1]  # Rejoin all but last part without dots and last part with a dot\n",
    "    elif len(parts) == 2:\n",
    "        value = value  # Already correctly formatted\n",
    "    # Convert to float\n",
    "    try:\n",
    "        return float(value)\n",
    "    except ValueError:\n",
    "        return 0.0  # In case of any unexpected format that still fails, return 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e67be4-21d5-45cf-98ed-e02d4957a2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated function to clean and convert square feet values to floats, handling multiple periods\n",
    "def clean_square_feet(value):\n",
    "    if pd.isna(value):\n",
    "        return 0.0\n",
    "    # Normalize the string by removing commas and extra spaces\n",
    "    value = str(value).replace(',', '').replace(' ', '')\n",
    "    # Handle cases with multiple periods\n",
    "    parts = value.split('.')\n",
    "    if len(parts) > 2:\n",
    "        value = ''.join(parts[:-1]) + '.' + parts[-1]  # Rejoin all but last part without dots and last part with a dot\n",
    "    elif len(parts) == 2:\n",
    "        value = value  # Already correctly formatted\n",
    "    # Convert to float\n",
    "    try:\n",
    "        return float(value)\n",
    "    except ValueError:\n",
    "        return 0.0  # In case of any unexpected format that still fails, return 0.0\n",
    "\n",
    "# Apply the cleaning function to the 'Square Feet' column\n",
    "aggregated_df['Square Feet'] = aggregated_df['Square Feet'].apply(clean_square_feet)\n",
    "\n",
    "# Summarize data: Total square feet and count of DCs by year and type\n",
    "summary_stats = aggregated_df.groupby(['Year', 'Type']).agg({'Square Feet': 'sum', 'Count': 'sum'}).reset_index()\n",
    "summary_stats.sort_values(by='Year', inplace=True)\n",
    "summary_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e290cb8-7852-435b-82fe-e91747c85b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total distribution centers from the summary statistics\n",
    "total_centers_from_summary = summary_stats['Count'].sum()\n",
    "\n",
    "# Calculate the total number of entries across all sheets\n",
    "total_centers_from_sheets = sum([sheet.shape[0] for sheet in cleaned_sheets.values()])\n",
    "\n",
    "total_centers_from_summary, total_centers_from_sheets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8e8699-29aa-4496-9076-6013c1899e23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d0146dc-b83e-45fa-8423-af36738ba004",
   "metadata": {},
   "source": [
    "## Contribution per distance/density to overall visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "177b0300-ffb7-426d-bf34-47859ae6503a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Number of Visitors from Each Distance:\n",
      "[246349.32784016 213723.67207287 180755.30112423 148806.53719399\n",
      " 118825.60543717  91539.55633158]\n",
      "\n",
      "Total Estimated Visitors by Distance: 1000000.0\n",
      "\n",
      "Total Visitors from Each Density:\n",
      "Density 1k: 9324 visitors\n",
      "Density 5k: 43427 visitors\n",
      "Density 10k: 78167 visitors\n",
      "Density 20k: 128660 visitors\n",
      "Density 50k: 206686 visitors\n",
      "Density 100k: 252781 visitors\n",
      "Density 250k: 280955 visitors\n",
      "\n",
      "Total Estimated Visitors by Density: 1000000.0000000001\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def estimate_visitor_distribution(total_visitors, prob_matrix, distances, densities):\n",
    "    # Calculate the proportion of total visitors from each density based on their relative values\n",
    "    density_norm_factor = prob_matrix.sum(axis=0)\n",
    "    density_norm = densities*density_norm_factor\n",
    "    density_proportions = density_norm/np.sum(density_norm)\n",
    "    \n",
    "    # Calculate the total number of visitors attributed to each density\n",
    "    visitors_per_density = density_proportions * total_visitors\n",
    "\n",
    "    # Create an empty array to store the estimated visitors for each distance across all densities\n",
    "    estimated_visitors_by_distance = np.zeros(len(distances))\n",
    "\n",
    "    # Distribute each density's visitors across distances according to the probability matrix\n",
    "    for i in range(len(densities)):\n",
    "        estimated_visitors_by_distance += prob_matrix[:, i] * visitors_per_density[i]\n",
    "\n",
    "    # Normalize the results to ensure they sum to the total number of visitors\n",
    "    estimated_visitors_by_distance *= (total_visitors / np.sum(estimated_visitors_by_distance))\n",
    "\n",
    "    return estimated_visitors_by_distance, visitors_per_density\n",
    "\n",
    "# Define the probability matrix, distances, and densities\n",
    "prob_matrix = np.array([\n",
    "    [0.999, 0.989, 0.966, 0.906, 0.717, 0.496, 0.236],\n",
    "    [0.999, 0.979, 0.941, 0.849, 0.610, 0.387, 0.172],\n",
    "    [0.997, 0.962, 0.899, 0.767, 0.490, 0.288, 0.123],\n",
    "    [0.995, 0.933, 0.834, 0.659, 0.372, 0.206, 0.086],\n",
    "    [0.989, 0.883, 0.739, 0.531, 0.268, 0.142, 0.060],\n",
    "    [0.978, 0.803, 0.615, 0.398, 0.184, 0.096, 0.041]\n",
    "])\n",
    "distances = np.array([0, 1, 2, 3, 4, 5])  # in miles\n",
    "densities = np.array([1, 5, 10, 20, 50, 100, 250])  # thousands of people within a 5-mile radius\n",
    "\n",
    "total_visitors = 1000000  # total number of visitors\n",
    "estimated_visitors, visitors_from_each_density = estimate_visitor_distribution(total_visitors, prob_matrix, distances, densities)\n",
    "\n",
    "print(\"Estimated Number of Visitors from Each Distance:\")\n",
    "print(estimated_visitors)\n",
    "print(\"\\nTotal Estimated Visitors by Distance:\", np.sum(estimated_visitors))\n",
    "\n",
    "# Print total visitors from each density\n",
    "print(\"\\nTotal Visitors from Each Density:\")\n",
    "for density, visitors in zip(densities, visitors_from_each_density):\n",
    "    print(f\"Density {density}k: {visitors:.0f} visitors\")\n",
    "\n",
    "print(\"\\nTotal Estimated Visitors by Density:\", np.sum(visitors_from_each_density))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d221c93-f004-4eb4-b1db-532508f92b43",
   "metadata": {},
   "source": [
    "## Scaling expenditure per consumer by square footage of store type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a13701b-5581-48af-ba02-710f9480ed0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weekly_visits = 167*1e6\n",
    "total_annual_visits = 167*1e6 * 52\n",
    "total_net_sales = 393247*1e6 \n",
    "avg_spend = (393247*1e6) / (8684*1e6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08270dee-7021-4af1-b0a3-bb088e32c7d7",
   "metadata": {},
   "source": [
    "## Monte Carlo Visitors + Average Spend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17eb22f1-0756-42dc-b5c2-07b99d2d48c1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Number of Visitors from Each Distance:\n",
      "[8.96033028e+09 7.23774679e+09 5.58534098e+09 4.12034037e+09\n",
      " 2.91903433e+09 1.99428754e+09]\n",
      "\n",
      "Total Estimated Visitors by Distance: 30817080291.5862\n",
      "\n",
      "Total Visitors from Each Density:\n",
      "Density 1k: 86204450 visitors\n",
      "Density 5k: 377854570 visitors\n",
      "Density 10k: 693066812 visitors\n",
      "Density 20k: 1105282172 visitors\n",
      "Density 50k: 1757664357 visitors\n",
      "Density 100k: 2207171340 visitors\n",
      "Density 250k: 2456756299 visitors\n",
      "\n",
      "Visitors by Store Type:\n",
      "Supercenters: 7594986482 visitors\n",
      "Discount Stores: 85763399 visitors\n",
      "Neighborhood Markets: 1003250119 visitors\n",
      "\n",
      "Visitors by Store Type:\n",
      "Supercenters: 7594986482 total visitors, 2125661 visitors per store\n",
      "Discount Stores: 85763399 total visitors, 231793 visitors per store\n",
      "Neighborhood Markets: 1003250119 total visitors, 1255632 visitors per store\n",
      "\n",
      "Total Estimated Visitors by Store Type: 8684000000.0\n",
      "\n",
      "Total Estimated Visitors by Density: 8684000000.0\n",
      "Average Estimated Visitors: 7596930936.6240835 85534327.06507833 1001534736.3108381\n",
      "Standard Deviation of Visitors: 16477077.721726427 696380.4113505094 16879244.064483777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Supercenters': 7594986481.958165,\n",
       " 'Discount Stores': 85763399.3862386,\n",
       " 'Neighborhood Markets': 1003250118.6555954}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def estimate_visitor_distribution_by_store_type(total_visitors, prob_matrix, distances, densities, store_data, num_simulations=1000):\n",
    "    # Calculate the proportion of total visitors from each density based on their relative values\n",
    "    # density_norm_factor = prob_matrix.sum(axis=0)\n",
    "    # density_norm = densities * density_norm_factor\n",
    "    # density_proportions = density_norm / np.sum(density_norm)\n",
    "\n",
    "    # Calculate the total number of visitors attributed to each density\n",
    "    visitor_results=[]\n",
    "    for _ in range(num_simulations):\n",
    "        # Randomly adjust probabilities by up to Â±10% to simulate changes in demographics or economic conditions\n",
    "        adjustment_factor = 1 + (np.random.rand(*prob_matrix.shape) - 0.5) * 0.2\n",
    "        adjusted_matrix = prob_matrix * adjustment_factor\n",
    "        density_norm_factor = adjusted_matrix.sum(axis=0)\n",
    "        density_norm = densities * density_norm_factor\n",
    "        density_proportions = density_norm / np.sum(density_norm)\n",
    "        \n",
    "        visitors_per_density = density_proportions * total_visitors\n",
    "\n",
    "    # Calculate total visitors based on store type and density eligibility\n",
    "        total_visitors_by_type = {}     \n",
    "        for store_type, data in store_data.items():\n",
    "            # Adjust the total visitors according to the store type specifics\n",
    "            footprint_ratio = data['avg_sqft'] / np.mean([d['avg_sqft'] for d in store_data.values()])\n",
    "            location_factor = data['locations'] / sum(d['locations'] for d in store_data.values())\n",
    "    \n",
    "            # Apply density eligibility\n",
    "            eligible_visitors_per_density = visitors_per_density * data['density_eligibility']\n",
    "            eligible_total_visitors = eligible_visitors_per_density.sum()  # Sum of eligible visitors per density\n",
    "    \n",
    "            # Calculate the share of visitors for this store type\n",
    "            raw_share = eligible_total_visitors * footprint_ratio * location_factor\n",
    "            total_visitors_by_type[store_type] = raw_share\n",
    "       \n",
    "    \n",
    "        # Normalize the visitor distribution to match the total number of visitors\n",
    "        sum_raw_shares = sum(total_visitors_by_type.values())\n",
    "        normalization_factor = total_visitors / sum_raw_shares\n",
    "        for store_type in total_visitors_by_type:\n",
    "            total_visitors_by_type[store_type] *= normalization_factor\n",
    "        \n",
    "        visitor_results.append(list(total_visitors_by_type.values()))\n",
    "\n",
    "        # Calculate and distribute visitors\n",
    "        estimated_visitors_by_distance = np.zeros(len(distances))\n",
    "        for store_type, visitors in total_visitors_by_type.items():\n",
    "            #visitor_results.append({store_type:visitors})\n",
    "            for i, is_eligible in enumerate(store_data[store_type]['density_eligibility']):\n",
    "                if is_eligible:\n",
    "                    estimated_visitors_by_distance += prob_matrix[:, i] * (eligible_visitors_per_density[i] * normalization_factor)\n",
    "\n",
    "    return estimated_visitors_by_distance, visitors_per_density, total_visitors_by_type, visitor_results\n",
    "\n",
    "# Store-specific data with density eligibility\n",
    "store_data = {\n",
    "    'Supercenters': {'locations': 3573, 'avg_sqft': 178000, 'density_eligibility': np.array([1, .8, .8, .8, 0.3, 0, 0])},\n",
    "    'Discount Stores': {'locations': 370, 'avg_sqft': 105000, 'density_eligibility': np.array([0, .2, .2, .2, 0, 0, 0])},\n",
    "    'Neighborhood Markets': {'locations': 799, 'avg_sqft': 42000, 'density_eligibility': np.array([0, 0, 0, 0, 0.7, 1, 1])}\n",
    "}\n",
    "\n",
    "estimated_visitors, visitors_from_each_density, visitors_by_store_type, visitor_results = estimate_visitor_distribution_by_store_type(\n",
    "    total_visitors=total_annual_visits, prob_matrix=prob_matrix, distances=distances, densities=densities, store_data=store_data)\n",
    "\n",
    "print(\"Estimated Number of Visitors from Each Distance:\")\n",
    "print(estimated_visitors)\n",
    "print(\"\\nTotal Estimated Visitors by Distance:\", np.sum(estimated_visitors))\n",
    "\n",
    "# Print total visitors from each density\n",
    "print(\"\\nTotal Visitors from Each Density:\")\n",
    "for density, visitors in zip(densities, visitors_from_each_density):\n",
    "    print(f\"Density {density}k: {visitors:.0f} visitors\")\n",
    "\n",
    "# Print visitors by store type\n",
    "print(\"\\nVisitors by Store Type:\")\n",
    "for store_type, visitors in visitors_by_store_type.items():\n",
    "    print(f\"{store_type}: {visitors:.0f} visitors\")\n",
    "\n",
    "# Print visitors by store type\n",
    "print(\"\\nVisitors by Store Type:\")\n",
    "\n",
    "visitors_per_store_by_type = {}\n",
    "for store_type, visitors in visitors_by_store_type.items():\n",
    "    visitors_per_store = visitors / store_data[store_type]['locations']\n",
    "    print(f\"{store_type}: {visitors:.0f} total visitors, {visitors_per_store:.0f} visitors per store\")\n",
    "    visitors_per_store_by_type[store_type] = visitors_per_store\n",
    "\n",
    "print(\"\\nTotal Estimated Visitors by Store Type:\", sum(visitors_by_store_type.values()))\n",
    "\n",
    "print(\"\\nTotal Estimated Visitors by Density:\", np.sum(visitors_from_each_density)) \n",
    "visitor_results = np.array(visitor_results)\n",
    "#visitor_results[:,1]\n",
    "# Analyze results\n",
    "print(\"Average Estimated Visitors:\", np.mean(visitor_results[:,0]),np.mean(visitor_results[:,1]),np.mean(visitor_results[:,2]))\n",
    "print(\"Standard Deviation of Visitors:\", np.std(visitor_results[:,0]),np.std(visitor_results[:,1]),np.std(visitor_results[:,2]))\n",
    "visitors_by_store_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8adad266-24ef-4f75-9f12-0a8fe97613fc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Normalized Spending per Store:\n",
      "Supercenters: $343052122497.31\n",
      "Discount Stores: $2958233745.57\n",
      "Neighborhood Markets: $47236643757.12\n",
      "\n",
      "Average Percent Spending by Store Type:\n",
      "Supercenters: 87.24%\n",
      "Discount Stores: 0.75%\n",
      "Neighborhood Markets: 12.01%\n",
      "\n",
      "Average Visitor Spending by Store Type:\n",
      "Supercenters: $45.19\n",
      "Discount Stores: $34.86\n",
      "Neighborhood Markets: $46.89\n",
      "Average Normalized Spending Total across Simulations: 393247000000.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Sample data\n",
    "visitors_data = {\n",
    "    'Supercenters': {'total_visitors': 7591667114, 'visitors_per_store': 2124732},\n",
    "    'Discount Stores': {'total_visitors': 84852921, 'visitors_per_store': 229332},\n",
    "    'Neighborhood Markets': {'total_visitors': 1007479965, 'visitors_per_store': 1260926}\n",
    "}\n",
    "total_revenue = total_net_sales  # Example total revenue\n",
    "\n",
    "# Define base average spending per visitor for each store type, initially unnormalized\n",
    "base_spending_per_visitor = {\n",
    "    'Supercenters': avg_spend,  # Hypothetical average spending per visitor\n",
    "    'Discount Stores': avg_spend,\n",
    "    'Neighborhood Markets': avg_spend\n",
    "}\n",
    "\n",
    "# Define potential variation ranges for scaling factors (e.g., influenced by e-commerce)\n",
    "scaling_factor_ranges = {\n",
    "    'Supercenters': (1.2, 1.4),\n",
    "    'Discount Stores': (.5, 1.5),\n",
    "    'Neighborhood Markets': (1, 1.7)\n",
    "}\n",
    "\n",
    "# Number of simulations\n",
    "n_simulations = 10000\n",
    "\n",
    "def monte_carlo_spending_adjustment(visitors_data, base_spending_per_visitor, scaling_factor_ranges, n_simulations, total_revenue):\n",
    "    results = []\n",
    "\n",
    "    for _ in range(n_simulations):\n",
    "        # Apply random scaling factors to the base spending per visitor\n",
    "        temp_spending = {store_type: base_spending_per_visitor[store_type] * np.random.uniform(*scaling_factor_ranges[store_type])\n",
    "                         for store_type in base_spending_per_visitor}\n",
    "        \n",
    "        # Normalize the spending using your existing function\n",
    "        normalized_spending, normalized_total, percent_spending = normalize_spending(visitors_data, temp_spending, total_revenue)\n",
    "        results.append((normalized_spending, normalized_total, percent_spending))\n",
    "    \n",
    "    return results\n",
    "\n",
    "def normalize_spending(visitors_data, base_spending_per_visitor, total_revenue):\n",
    "    # Calculate initial total spending\n",
    "    initial_total_spending = sum(base_spending_per_visitor[store_type] * data['total_visitors']\n",
    "                                 for store_type, data in visitors_data.items())\n",
    "    \n",
    "    # Normalization factor to match the total revenue\n",
    "    normalization_factor = total_revenue / initial_total_spending\n",
    "    \n",
    "    # Adjusted spending per visitor\n",
    "    normalized_spending_per_visitor = {store_type: base_spending_per_visitor[store_type] * normalization_factor\n",
    "                                       for store_type in base_spending_per_visitor}\n",
    "    \n",
    "    normalized_spending_total = sum(normalized_spending_per_visitor[store_type] * data['total_visitors']\n",
    "                                    for store_type, data in visitors_data.items())\n",
    "\n",
    "    normalized_spending_per_store = {store_type: normalized_spending_per_visitor[store_type] * data['total_visitors']\n",
    "                                       for store_type, data in visitors_data.items()}\n",
    "    \n",
    "    percent_spending_per_store = {store_type: normalized_spending_per_store[store_type] / normalized_spending_total\n",
    "                                       for store_type in normalized_spending_per_store}\n",
    "    \n",
    "    return normalized_spending_per_visitor, normalized_spending_total, percent_spending_per_store\n",
    "\n",
    "def calculate_averages(simulation_results):\n",
    "    # Initialize dictionaries to accumulate totals for averaging later\n",
    "    total_normalized_spending_per_store = {store_type: 0 for store_type in visitors_data}\n",
    "    total_percent_spending_per_store = {store_type: 0 for store_type in visitors_data}\n",
    "    total_normalized_spending_per_visitor = {store_type: 0 for store_type in visitors_data}\n",
    "    \n",
    "    # Accumulate totals from each simulation\n",
    "    for normalized_spending, normalized_total, percent_spending in simulation_results:\n",
    "        for store_type in visitors_data:\n",
    "            total_normalized_spending_per_store[store_type] += normalized_spending[store_type] * visitors_data[store_type]['total_visitors']\n",
    "            total_percent_spending_per_store[store_type] += percent_spending[store_type]\n",
    "            total_normalized_spending_per_visitor[store_type] += normalized_spending[store_type]\n",
    "            \n",
    "    # Calculate averages by dividing by the number of simulations\n",
    "    avg_normalized_spending_per_store = {store_type: total / n_simulations for store_type, total in total_normalized_spending_per_store.items()}\n",
    "    avg_percent_spending_per_store = {store_type: total / n_simulations for store_type, total in total_percent_spending_per_store.items()}\n",
    "    avg_normalized_spending_per_visitor = {store_type: total / n_simulations for store_type, total in total_normalized_spending_per_visitor.items()}\n",
    "    \n",
    "    return avg_normalized_spending_per_store, avg_percent_spending_per_store, avg_normalized_spending_per_visitor\n",
    "\n",
    "\n",
    "\n",
    "# Run the Monte Carlo simulation\n",
    "simulation_results = monte_carlo_spending_adjustment(visitors_data, base_spending_per_visitor, scaling_factor_ranges, n_simulations, total_revenue)\n",
    "\n",
    "\n",
    "# Get averages from the simulation results\n",
    "avg_normalized_spending_per_store, avg_percent_spending_per_store, avg_normalized_spending_per_visitor = calculate_averages(simulation_results)\n",
    "\n",
    "# Printing the averages\n",
    "print(\"Average Normalized Spending per Store:\")\n",
    "for store_type, avg_spending in avg_normalized_spending_per_store.items():\n",
    "    print(f\"{store_type}: ${avg_spending:.2f}\")\n",
    "\n",
    "print(\"\\nAverage Percent Spending by Store Type:\")\n",
    "for store_type, avg_percent in avg_percent_spending_per_store.items():\n",
    "    print(f\"{store_type}: {avg_percent * 100:.2f}%\")\n",
    "\n",
    "print(\"\\nAverage Visitor Spending by Store Type:\")\n",
    "for store_type, avg_spending in avg_normalized_spending_per_visitor.items():\n",
    "    print(f\"{store_type}: ${avg_spending:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example output\n",
    "average_results = np.mean([result[1] for result in simulation_results])\n",
    "print(\"Average Normalized Spending Total across Simulations:\", average_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ad79fa-bb45-4011-bfff-89641602846a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e0ba436-b54e-4b31-9df9-f9d2f78e6fab",
   "metadata": {},
   "source": [
    "## The Expansion Simulation Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d856fb8-39a8-43e2-a491-baf7cb1d50be",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1,   5,  10,  20,  50, 100, 250]),\n",
       " array([[0.999, 0.989, 0.966, 0.906, 0.717, 0.496, 0.236],\n",
       "        [0.999, 0.979, 0.941, 0.849, 0.61 , 0.387, 0.172],\n",
       "        [0.997, 0.962, 0.899, 0.767, 0.49 , 0.288, 0.123],\n",
       "        [0.995, 0.933, 0.834, 0.659, 0.372, 0.206, 0.086],\n",
       "        [0.989, 0.883, 0.739, 0.531, 0.268, 0.142, 0.06 ],\n",
       "        [0.978, 0.803, 0.615, 0.398, 0.184, 0.096, 0.041]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "densities, prob_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e23e40a-4bf4-4d00-88f1-409e327dba3a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (1915993438.py, line 83)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[25], line 83\u001b[0;36m\u001b[0m\n\u001b[0;31m    results = {}\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class \n",
    "    def __init__(self, demographic_data, market_conditions, financials, investment_factors, historical_data, store_data, prob_matrix, distances, densities, avg_spending_per_visitor):\n",
    "        self.demographic_data = demographic_data\n",
    "        self.market_conditions = market_conditions\n",
    "        self.financials = financials\n",
    "        self.investment_factors = investment_factors\n",
    "        self.historical_data = historical_data\n",
    "        self.store_data = store_data\n",
    "        self.prob_matrix = prob_matrix\n",
    "        self.distances = distances\n",
    "        self.densities = densities\n",
    "        self.avg_spending_per_visitor = avg_spending_per_visitor\n",
    "        self.visitor_estimates = None\n",
    "\n",
    "    \n",
    "    def calculate_cagr(self, initial_value, final_value, periods):\n",
    "        if periods <= 0:\n",
    "            raise ValueError(\"Periods must be greater than zero for CAGR calculation.\")\n",
    "        return (final_value / initial_value) ** (1 / periods) - 1\n",
    "\n",
    "    def calculate_cagrs(self):\n",
    "        revenue_cagr = self.calculate_cagr(\n",
    "            self.historical_data['initial_revenue'],\n",
    "            self.historical_data['final_revenue'],\n",
    "            self.historical_data['periods'])\n",
    "        cogs_cagr = self.calculate_cagr(\n",
    "            self.historical_data['initial_cogs'],\n",
    "            self.historical_data['final_cogs'],\n",
    "            self.historical_data['periods'])\n",
    "        ecommerce_cagr = self.calculate_cagr(\n",
    "            self.historical_data['initial_ecommerce'],\n",
    "            self.historical_data['final_ecommerce'],\n",
    "            self.historical_data['periods'])\n",
    "        return revenue_cagr, cogs_cagr, ecommerce_cagr\n",
    "\n",
    "    def calculate_cannibalization_effect(self, existing_store_sales, new_store_openings):\n",
    "        cannibalization_rate = self.market_conditions.get('cannibalization_rate', 0.01)\n",
    "        adjusted_sales = existing_store_sales * (1 - cannibalization_rate * new_store_openings)\n",
    "        return adjusted_sales\n",
    "\n",
    "    def dynamic_ecommerce_growth(self, current_sales):\n",
    "        ecommerce_growth_factor = self.market_conditions.get('ecommerce_growth_factor', 0.05)\n",
    "        market_saturation = self.market_conditions.get('market_saturation', 0.1)\n",
    "        distribution_efficiency = self.market_conditions.get('distribution_efficiency', 0.9)\n",
    "        adjusted_growth_rate = ecommerce_growth_factor * (1 - market_saturation) * distribution_efficiency\n",
    "        adjusted_sales = current_sales * (1 + adjusted_growth_rate)\n",
    "        return adjusted_sales\n",
    "\n",
    "    def adjust_operational_costs(self, base_cost):\n",
    "        proximity_factor = self.market_conditions.get('proximity_factor', 0.2)\n",
    "        distribution_center_proximity = self.market_conditions.get('distribution_center_proximity', 0.5)\n",
    "        adjusted_cost = base_cost * (1 - proximity_factor * distribution_center_proximity)\n",
    "        return adjusted_cost\n",
    "\n",
    "    def labor_investment_needed(self, current_market_share, target_market_share, community_opposition_strength):\n",
    "        labor_investment_increase = 0\n",
    "        while current_market_share < target_market_share:\n",
    "            current_market_share *= (1 + 0.01 * (1 - community_opposition_strength))\n",
    "            labor_investment_increase += 0.01\n",
    "        return labor_investment_increase\n",
    "\n",
    "    def evaluate_labor_investment_impact(self, labor_costs, initial_profit_margin, labor_investment_increase):\n",
    "        adjusted_labor_costs = labor_costs * (1 + labor_investment_increase)\n",
    "        adjusted_profit_margin = initial_profit_margin * (1 - 0.05 * labor_investment_increase)\n",
    "        return adjusted_labor_costs, adjusted_profit_margin\n",
    "\n",
    "\n",
    "    def estimate_visitors(self, total_visitors):\n",
    "        # Call the visitor distribution estimation function\n",
    "        estimated_visitors, visitors_from_each_density, visitors_by_store_type, visitor_results = estimate_visitor_distribution_by_store_type(\n",
    "            total_visitors=total_visitors, prob_matrix=self.prob_matrix, distances=self.distances, densities=self.densities, store_data=self.store_data)\n",
    "        self.visitor_estimates = {\n",
    "            'estimated_visitors': estimated_visitors,\n",
    "            'visitors_from_each_density': visitors_from_each_density,\n",
    "            'visitors_by_store_type': visitors_by_store_type,\n",
    "            'visitor_results': visitor_results\n",
    "        }\n",
    "        return self.visitor_estimates\n",
    "\n",
    "    def simulate_store_numbers(visitors_by_store_type, optimal_visitors, max_stores, store_type):\n",
    "    results = {}\n",
    "    for num_stores in range(1, max_stores + 1):\n",
    "        visitors_per_store = visitors_by_store_type[store_type] / (store_data[store_type]['locations'] + num_stores)\n",
    "        if visitors_per_store < optimal_visitors:\n",
    "            # Assuming profitability drops if the store is underutilized\n",
    "            profitability = visitors_per_store / optimal_visitors * 100  # as percentage\n",
    "        else:\n",
    "            # Assuming maximum profitability is reached at optimal visitors per store\n",
    "            profitability = 100\n",
    "\n",
    "        results[num_stores] = (visitors_per_store, profitability)\n",
    "        if visitors_per_store < optimal_visitors:\n",
    "            break  # Stop if stores are not reaching optimal visitor count\n",
    "\n",
    "        return results\n",
    "    \n",
    "    def run_monte_carlo_simulations(self, num_simulations=1000, total_visitors=167000000):\n",
    "        # Estimate visitor distribution\n",
    "        self.estimate_visitors(total_visitors)\n",
    "\n",
    "        results = []\n",
    "        for _ in range(num_simulations):\n",
    "            # Example of utilizing visitor counts\n",
    "            for store_type, visitors in self.visitor_estimates['visitors_by_store_type'].items():\n",
    "                current_sales = visitors * self.avg_spending_per_visitor.get(store_type, 20)  # Assuming a default average spend if not specified\n",
    "                adjusted_sales = self.calculate_cannibalization_effect(current_sales, np.random.randint(1, 10))\n",
    "                adjusted_sales = self.dynamic_ecommerce_growth(adjusted_sales)\n",
    "                adjusted_costs = self.adjust_operational_costs(self.financials['base_operational_cost'])\n",
    "                net_profit = adjusted_sales - adjusted_costs\n",
    "                results.append(net_profit)\n",
    "\n",
    "        average_profit = np.mean(results)\n",
    "        profit_std_dev = np.std(results)\n",
    "        return average_profit, profit_std_dev\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7342431d-36a6-4547-8a12-74b426e2f56f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16861918-3417-4dfe-8155-d9852a9e833a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Supercenters': 7593519993.959026, 'Discount Stores': 85181880.42132439, 'Neighborhood Markets': 1005298125.6196477}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: (1256622.6570245596, 100),\n",
       " 2: (1255053.8397249035, 100),\n",
       " 3: (1253488.93468784, 100),\n",
       " 4: (1251927.9272971952, 100),\n",
       " 5: (1250370.8030095121, 100),\n",
       " 6: (1248817.5473535997, 100),\n",
       " 7: (1247268.145930084, 100),\n",
       " 8: (1245722.5844109638, 100),\n",
       " 9: (1244180.848539168, 100),\n",
       " 10: (1242642.9241281184, 100),\n",
       " 11: (1241108.7970612936, 100),\n",
       " 12: (1239578.4532917975, 100),\n",
       " 13: (1238051.8788419308, 100),\n",
       " 14: (1236529.0598027648, 100),\n",
       " 15: (1235009.9823337195, 100),\n",
       " 16: (1233494.6326621445, 100),\n",
       " 17: (1231982.9970829017, 100),\n",
       " 18: (1230475.0619579533, 100),\n",
       " 19: (1228970.8137159508, 100),\n",
       " 20: (1227470.2388518287, 100),\n",
       " 21: (1225973.3239263997, 100),\n",
       " 22: (1224480.0555659535, 100),\n",
       " 23: (1222990.4204618586, 100),\n",
       " 24: (1221504.4053701675, 100),\n",
       " 25: (1220021.997111223, 100),\n",
       " 26: (1218543.18256927, 100),\n",
       " 27: (1217067.9486920675, 100),\n",
       " 28: (1215596.2824905051, 100),\n",
       " 29: (1214128.1710382218, 100),\n",
       " 30: (1212663.6014712276, 100),\n",
       " 31: (1211202.5609875275, 100),\n",
       " 32: (1209745.036846748, 100),\n",
       " 33: (1208291.016369769, 100),\n",
       " 34: (1206840.4869383527, 100),\n",
       " 35: (1205393.4359947816, 100),\n",
       " 36: (1203949.8510414944, 100),\n",
       " 37: (1202509.719640727, 100),\n",
       " 38: (1201073.029414155, 100),\n",
       " 39: (1199639.768042539, 99.96998067021158)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimated_visitors, visitors_from_each_density, visitors_by_store_type, visitor_results = estimate_visitor_distribution_by_store_type(\n",
    "total_visitors=total_annual_visits, prob_matrix=prob_matrix, distances=distances, densities=densities, store_data=store_data)\n",
    "print(visitors_by_store_type)\n",
    "def simulate_store_numbers(visitors_by_store_type, optimal_visitors, max_stores, store_type):\n",
    "    results = {}\n",
    "    for num_stores in range(1, max_stores + 1):\n",
    "        visitors_per_store = visitors_by_store_type[store_type] / (store_data[store_type]['locations'] + num_stores)\n",
    "        if visitors_per_store < optimal_visitors:\n",
    "            # Assuming profitability drops if the store is underutilized\n",
    "            profitability = visitors_per_store / optimal_visitors * 100  # as percentage\n",
    "        else:\n",
    "            # Assuming maximum profitability is reached at optimal visitors per store\n",
    "            profitability = 100\n",
    "\n",
    "        results[num_stores] = (visitors_per_store, profitability)\n",
    "        if visitors_per_store < optimal_visitors:\n",
    "            break  # Stop if stores are not reaching optimal visitor count\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Optimal visitors per store for efficient operation\n",
    "optimal_visitors_per_store = 1200000\n",
    "\n",
    "\n",
    "max_possible_stores = 50  # Set based on your market size and investment capability\n",
    "simulation_results = simulate_store_numbers(visitors_by_store_type, optimal_visitors_per_store, max_possible_stores, 'Neighborhood Markets')\n",
    "\n",
    "simulation_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34f350cd-2838-45fc-a0b3-a2a0d26e5789",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Profit from Simulations: 1902980990.583824\n",
      "Profit Standard Deviation: 2241445108.6590276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "910844475.3862766"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_matrix = np.array([\n",
    "    [0.999, 0.989, 0.966, 0.906, 0.717, 0.496, 0.236],\n",
    "    [0.999, 0.979, 0.941, 0.849, 0.610, 0.387, 0.172],\n",
    "    [0.997, 0.962, 0.899, 0.767, 0.490, 0.288, 0.123],\n",
    "    [0.995, 0.933, 0.834, 0.659, 0.372, 0.206, 0.086],\n",
    "    [0.989, 0.883, 0.739, 0.531, 0.268, 0.142, 0.060],\n",
    "    [0.978, 0.803, 0.615, 0.398, 0.184, 0.096, 0.041]\n",
    "])\n",
    "distances = np.array([0, 1, 2, 3, 4, 5])  # in miles\n",
    "densities = np.array([1, 5, 10, 20, 50, 100, 250])  # thousands of people within a 5-mile radius\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example usage of the class:\n",
    "model = NeighborhoodMarketExpansionModel(\n",
    "    demographic_data={},\n",
    "    market_conditions={\"cannibalization_rate\": 0.01, \"ecommerce_growth_factor\": 0.05},\n",
    "    financials={ \"base_operational_cost\": 20000, \"investment\": 100000},\n",
    "    investment_factors={},\n",
    "    historical_data={},\n",
    "    prob_matrix=prob_matrix,\n",
    "    densities=densities,\n",
    "    store_data = {\n",
    "    'Supercenters': {'locations': 3573, 'avg_sqft': 178000, 'density_eligibility': np.array([1, .8, .8, .8, 0.3, 0, 0])},\n",
    "    'Discount Stores': {'locations': 370, 'avg_sqft': 105000, 'density_eligibility': np.array([0, .2, .2, .2, 0, 0, 0])},\n",
    "    'Neighborhood Markets': {'locations': 799, 'avg_sqft': 42000, 'density_eligibility': np.array([0, 0, 0, 0, 0.7, 1, 1])}\n",
    "},\n",
    "    distances=distances,\n",
    "    avg_spending_per_visitor = {'Supercenters': 35.0, 'Discount Stores': 28.5, 'Neighborhood Markets': 32.0}\n",
    ")\n",
    "cann=model.calculate_cannibalization_effect(1000927994.9299742,9)\n",
    "average_profit, profit_std_dev = model.run_monte_carlo_simulations()\n",
    "print(f\"Average Profit from Simulations: {average_profit}\")\n",
    "print(f\"Profit Standard Deviation: {profit_std_dev}\")\n",
    "\n",
    "cann\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe07ee1f-a492-45bb-918a-57b0ca9e92fc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NeighborhoodMarketExpansionModel:\n",
    "    def __init__(self, demographic_data, market_conditions, financials, investment_factors, historical_data, store_data, prob_matrix, distances, densities, avg_spending_per_visitor, financial_forecast):\n",
    "        self.demographic_data = demographic_data\n",
    "        self.market_conditions = market_conditions\n",
    "        self.financials = financials\n",
    "        self.investment_factors = investment_factors\n",
    "        self.historical_data = historical_data\n",
    "        self.store_data = store_data\n",
    "        self.prob_matrix = prob_matrix\n",
    "        self.distances = distances\n",
    "        self.densities = densities\n",
    "        self.avg_spending_per_visitor = avg_spending_per_visitor\n",
    "        self.financial_forecast = financial_forecast  # Baseline financial data\n",
    "        self.visitor_estimates = None\n",
    "\n",
    "    # Existing methods...\n",
    "\n",
    "    def update_financial_forecasts(self, num_new_stores, store_type):\n",
    "        # Placeholder for updating financial forecasts based on new stores\n",
    "        # This would typically modify self.financial_forecast based on estimated additional revenue, costs, and asset changes\n",
    "        revenue_increase = num_new_stores * self.estimate_additional_revenue_per_store(store_type)\n",
    "        new_assets_value = num_new_stores * self.store_data[store_type]['average_asset_value']\n",
    "        self.financial_forecast['Operating revenue (Turnover)'] += revenue_increase\n",
    "        self.financial_forecast['Total assets'] += new_assets_value\n",
    "        # More adjustments can be added here\n",
    "\n",
    "    def estimate_additional_revenue_per_store(self, store_type):\n",
    "        # Estimate additional revenue per store - this could use historical data or market analysis\n",
    "        return 20000  # Example fixed value\n",
    "\n",
    "    def simulate_store_impact(self, max_new_stores, store_type):\n",
    "        # Simulate financial impact for adding up to max_new_stores\n",
    "        for num_stores in range(1, max_new_stores + 1):\n",
    "            self.update_financial_forecasts(num_stores, store_type)\n",
    "            print(f\"After adding {num_stores} {store_type} stores: Updated Financial Forecast\")\n",
    "\n",
    "# Example instantiation and usage:\n",
    "model = NeighborhoodMarketExpansionModel(demographic_data, market_conditions, financials, investment_factors, historical_data, store_data, prob_matrix, distances, densities, avg_spending_per_visitor, financial_forecast)\n",
    "model.simulate_store_impact(5, 'Neighborhood markets')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09e8c16-4c0a-4d8d-a88b-de4668ca7235",
   "metadata": {},
   "source": [
    "## Trying to workout expenses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b787958c-28a0-4cff-85de-f1672cd04bd8",
   "metadata": {},
   "source": [
    "## Additional insights from appendices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d92b80-4d1b-43d7-9076-b36a95e03d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WalmartFinancialModel:\n",
    "    # Existing methods...\n",
    "\n",
    "    def calculate_supply_chain_efficiencies(self, automation_investments, year):\n",
    "        # Estimate cost savings and revenue impacts from supply chain automation\n",
    "        savings = automation_investments * 0.05  # Assuming 5% cost saving from automation\n",
    "        additional_revenue = savings * 3  # Hypothetical multiplier for revenue from improved delivery speeds\n",
    "        return savings, additional_revenue\n",
    "    \n",
    "    def evaluate_membership_programs(self, subscribers, subscription_fee):\n",
    "        # Calculate revenue from subscription-based models like Walmart+\n",
    "        return subscribers * subscription_fee\n",
    "\n",
    "    def scenario_analysis(self, base_case_parameters, scenarios):\n",
    "        # Conduct scenario analysis based on varying parameters\n",
    "        results = {}\n",
    "        for scenario, params in scenarios.items():\n",
    "            self.update_market_conditions(params)  # Method to dynamically adjust market conditions\n",
    "            results[scenario] = self.run_financial_forecast()\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be59d47f-9977-463d-b340-dc864364866d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SupplyChainModel:\n",
    "    def __init__(self, initial_investment, efficiency_rate, revenue_growth_rate,distribution_sqft_demand):\n",
    "        self.initial_investment = initial_investment\n",
    "        self.efficiency_rate = cost_savings_rate  # Percentage of operational cost savings\n",
    "        self.revenue_growth_rate = revenue_growth_rate  # Additional revenue growth from enhanced capabilities\n",
    "        self.distribution_sqft_demand\n",
    "\n",
    "    def calculate_costs(self, operational_costs):\n",
    "        # Calculate cost savings based on the initial investment and operational cost savings rate\n",
    "        costs = { coef\tstd err\tt\tP>|t|\t[0.025\t0.975]\n",
    "Discount stores\t12.5885\t1.454\t8.660\t0.000\t9.588\t15.589\n",
    "Supercenters\t16.2044\t3.715\t4.361\t0.000\t8.536\t23.873\n",
    "Neighborhood markets\t26.8763\t9.679\t2.777\t0.010\t6.899\t46.854\n",
    "Capital Expenditures\t-3.1922\t0.655\t-4.872\t0.000\t-4.545\t-1.840} \n",
    "        savings = operational_costs * self.cost_savings_rate\n",
    "        return savings\n",
    "\n",
    "    def calculate_revenue_growth(self, base_revenue):\n",
    "        # Calculate additional revenue generated from investments\n",
    "        additional_revenue = base_revenue * self.revenue_growth_rate\n",
    "        return additional_revenue\n",
    "\n",
    "    def simulate_financial_impact(self, operational_costs, base_revenue):\n",
    "        # Calculate both cost savings and additional revenue\n",
    "        savings = self.calculate_cost_savings(operational_costs)\n",
    "        additional_revenue = self.calculate_revenue_growth(base_revenue)\n",
    "        \n",
    "        # Net effect on operations\n",
    "        net_operational_costs = operational_costs - savings\n",
    "        net_revenue = base_revenue + additional_revenue\n",
    "\n",
    "        return net_operational_costs, net_revenue\n",
    "\n",
    "# # Example usage\n",
    "# initial_investment = 50000000  # $50 million\n",
    "# operational_costs = 100000000  # $100 million annual operational costs\n",
    "# base_revenue = 500000000  # $500 million base revenue\n",
    "\n",
    "# supply_chain_model = SupplyChainModel(initial_investment, cost_savings_rate=0.1, revenue_growth_rate=0.05)\n",
    "# net_costs, net_revenue = supply_chain_model.simulate_financial_impact(operational_costs, base_revenue)\n",
    "\n",
    "# print(f\"Net Operational Costs after Savings: ${net_costs}\")\n",
    "# print(f\"Net Revenue after Investment: ${net_revenue}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e16204-e0ea-4962-81f0-9e4081df8ad3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ECommerceGrowth:\n",
    "    def __init__(self, base_sales, growth_rate, subscribers, subscription_fee, fulfillment_impact):\n",
    "        self.base_sales = base_sales\n",
    "        self.growth_rate = growth_rate\n",
    "        self.subscribers = subscribers\n",
    "        self.subscription_fee = subscription_fee\n",
    "        self.fulfillment_impact = fulfillment_impact\n",
    "\n",
    "    def calculate_incremental_revenue_from_subscriptions(self):\n",
    "        # Direct revenue from subscriptions\n",
    "        direct_revenue = self.subscribers * self.subscription_fee\n",
    "        \n",
    "        # Indirect revenue could be modeled based on increased purchase frequency\n",
    "        # Assuming a 5% increase in overall purchases due to membership benefits\n",
    "        indirect_revenue = self.base_sales * 0.05\n",
    "        return direct_revenue + indirect_revenue\n",
    "\n",
    "    def calculate_revenue_from_fulfillment_expansion(self):\n",
    "        # Additional revenue from enhanced fulfillment capabilities\n",
    "        # Assuming a 3% increase in sales due to better customer service and faster delivery\n",
    "        additional_revenue = self.base_sales * self.fulfillment_impact\n",
    "        return additional_revenue\n",
    "\n",
    "    def simulate_e_commerce_growth(self):\n",
    "        # Calculate total e-commerce growth including Walmart+ and fulfillment impacts\n",
    "        subscription_revenue = self.calculate_incremental_revenue_from_subscriptions()\n",
    "        fulfillment_revenue = self.calculate_revenue_from_fulfillment_expansion()\n",
    "        total_revenue = self.base_sales + subscription_revenue + fulfillment_revenue\n",
    "        return total_revenue\n",
    "\n",
    "# # Example usage\n",
    "# ecommerce_growth = ECommerceGrowth(base_sales=100000000, growth_rate=0.1, subscribers=1000000, subscription_fee=98, fulfillment_impact=0.03)\n",
    "# total_revenue = ecommerce_growth.simulate_e_commerce_growth()\n",
    "\n",
    "# print(f\"Total Projected E-Commerce Revenue: ${total_revenue}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd4ec3a-7b68-4e3b-97e6-89a4966d71cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the SupplyChainModel to focus exclusively on cost savings\n",
    "class SupplyChainModel:\n",
    "    def __init__(self, initial_investment, cost_savings_rate):\n",
    "        self.initial_investment = initial_investment\n",
    "        self.cost_savings_rate = cost_savings_rate  # Only focus on cost savings\n",
    "\n",
    "    def calculate_cost_savings(self, operational_costs):\n",
    "        # Calculate cost savings based on operational efficiencies\n",
    "        return operational_costs * self.cost_savings_rate\n",
    "\n",
    "# Redefine the ECommerceGrowth to explicitly cover all revenue impacts, removing generic revenue growth from supply chain improvements\n",
    "class ECommerceGrowth:\n",
    "    def __init__(self, base_sales, subscribers, subscription_fee, fulfillment_impact):\n",
    "        self.base_sales = base_sales\n",
    "        self.subscribers = subscribers\n",
    "        self.subscription_fee = subscription_fee\n",
    "        self.fulfillment_impact = fulfillment_impact  # Include all revenue enhancements from fulfillment\n",
    "\n",
    "    def simulate_e_commerce_growth(self):\n",
    "        # Calculate direct revenue from subscriptions\n",
    "        direct_revenue = self.subscribers * self.subscription_fee\n",
    "        # Revenue from enhanced fulfillment capabilities\n",
    "        additional_revenue = self.base_sales * (0.05 + self.fulfillment_impact)  # Include indirect revenue from subscriptions and fulfillment improvements\n",
    "        return self.base_sales + direct_revenue + additional_revenue\n",
    "\n",
    "# This adjustment ensures that the revenue from supply chain improvements is not double-counted with the fulfillment enhancements in ECommerceGrowth.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5128a6-81f0-4a49-b481-2bbdbadab433",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class FinancialModel:\n",
    "    def __init__(self, base_sales, operational_costs, supply_chain_params, ecommerce_params):\n",
    "        self.base_sales = base_sales\n",
    "        self.operational_costs = operational_costs\n",
    "        self.supply_chain_model = SupplyChainModel(**supply_chain_params)\n",
    "        self.ecommerce_growth = ECommerceGrowth(**ecommerce_params)\n",
    "\n",
    "    def run_simulation(self, num_simulations=1000):\n",
    "        results = []\n",
    "        for _ in range(num_simulations):\n",
    "            # Randomly generate input parameters from assumed distributions\n",
    "            sampled_operational_costs = np.random.normal(self.operational_costs, self.operational_costs * 0.1)  # 10% SD\n",
    "            sampled_base_sales = np.random.normal(self.base_sales, self.base_sales * 0.1)  # 10% SD\n",
    "\n",
    "            # Calculate impacts from each model component\n",
    "            net_operational_costs = self.supply_chain_model.calculate_cost_savings(sampled_operational_costs)\n",
    "            net_revenue = self.ecommerce_growth.simulate_e_commerce_growth()\n",
    "\n",
    "            # Calculate net profit or other financial metrics\n",
    "            net_profit = net_revenue - net_operational_costs\n",
    "            results.append(net_profit)\n",
    "\n",
    "        return np.mean(results), np.std(results)  # Return average and standard deviation of results\n",
    "\n",
    "# Example usage with some hypothetical parameters\n",
    "params = {\n",
    "    'base_sales': 500000000,\n",
    "    'operational_costs': 100000000,\n",
    "    'supply_chain_params': {'initial_investment': 50000000, 'cost_savings_rate': 0.05},\n",
    "    'ecommerce_params': {'base_sales': 500000000, 'subscribers': 1000000, 'subscription_fee': 98, 'fulfillment_impact': 0.03}\n",
    "}\n",
    "model = FinancialModel(**params)\n",
    "average_profit, profit_std_dev = model.run_simulation(num_simulations=10000)\n",
    "\n",
    "print(f\"Average Projected Profit: ${average_profit:.2f}\")\n",
    "print(f\"Profit Standard Deviation: ${profit_std_dev:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
